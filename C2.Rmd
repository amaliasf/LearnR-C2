---
title: "Classification 2"
author : "Team Algoritma"
date : "February 13, 2022"
output: 
  learnr::tutorial:
  fig.show : 'asis'
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr) # user interface for coding exercise
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
# options(scipen = 99)
# Sys.setlocale('LC_ALL','C')

library(dplyr) # data manipulation
library(e1071) # naive bayes model 
library(caret) # classification training
library(ROCR) # roc
library(tm) # text mining
library(SnowballC) # stemmer
library(rsample) # resampling on splitting
library(partykit) # decision tree model 
library(randomForest) # random forest model 
# theme_set(theme_minimal())
```



## Bab 1 : Naive Bayes

Halo _Future Data Scientist!_ Pada _course_ ini kita akan belajar lebih lanjut mengenai metode klasifikasi. Kalau pada _course_ sebelumnya yaitu _Classification 1_ kita sudah mengenal 2 algoritma klasifikasi yang sangat popular yaitu _Logistic Regression_ dan _K-Nearest Neighbor_, kali ini kita diberi kesempatan untuk belajar beberapa algoritma lain yang lebih _advance_ lagi. Namun tidak perlu khawatir, karena secara workflow sama saja seperti pada _Classification 1_, hanya metode saja yang berbeda. Algoritma pertama yang akan kita pelajari adalah _Naive Bayes_. 

Naive Bayes adalah suatu algoritma klasifikasi yang didasari oleh _Bayes' Theorem of Probability_. Faktanya, teorema Bayes amat sering digunakan pada kehidupan sehari-hari. 

### Theory of Probability

Saat kita menghitung peluang 2 atau lebih kejadian terjadi bersamaan, kita dapat menghitungnya dengan 2 cara:

1. _Independent Event_: Peluang kejadian A tidak mempengaruhi peluang kejadian B. 
Contoh: Peluang dadu keluar angka 4 pada lemparan pertama dan peluang keluar angka 6 pada lemparan kedua
Peluang 2 kejadian independen yang dapat terjadi secara bersamaan adalah hasil perkalian peluang masing-masing kejadian tersebut.

$$P(A \cap B) = P(A) \times P(B)$$ 

2. _Dependent Event_: Peluang kejadian A dipengaruhi oleh peluang kejadian B (informasi tentang kejadian B). 
Contoh: Peluang banjir di Jakarta jika diketahui hujan deras di Bogor
Untuk menghitung peluangnya, kita menggunakan _Bayes Theorem_:

$$P(A|B) = \frac{P(B|A) P(A)}{P(B|A) P(A)\ +\  P(B|\neg A) P(\neg A)}$$
Keterangan:

$P(A|B)$ = Peluang terjadi A jika diketahui B telah terjadi.

$P(B|\neg A)$ = Peluang tidak terjadi A jika diketahui B telah terjadi.

$P(A)$ = Peluang terjadi A

$P(\neg A)$ = Peluang tidak terjadi A


### Characteristics of Naive Bayes

Naive Bayes mengklasifikasi berdasarkan peluang dependen antara prediktor dengan target variabel. Namun, Naive Bayes mengasumsikan tiap prediktor saling independen (tidak berhubungan satu sama lain) dan memiliki bobot yang sama untuk menghasilkan prediksi. Oleh karena itu dinamakan "Naive". Hal ini untuk memudahkan kalkulasi dan mengurangi beban komputasi.

Karakteristik selanjutnya dari Naive Bayes adalah _Skewness Due To Scarcity_. Ketika terdapat suatu prediktor yang frekuensi nilainya 0 untuk salah satu kelas , maka model secara otomatis memprediksi bahwa peluangya adalah 0 untuk kondisi tersebut, tanpa memperdulikan nilai dari prediktor yang lainnya. Solusi alternatif untuk menangani skewness due to data scarcity selain menghilangkan prediktor yang bermasalah tersebut adalah dengan metode _Laplace Smoothing_.

_Laplace Smoothing_ merupakan metode yang menambahkan frekuensi dari setiap prediktor sebanyak angka tertentu (biasanya 1), sehingga tidak ada prediktor yang memiliki nilai 0 dan harus dibuang.

### Study Case : Affiliation Classifier

Sebagai latihan untuk memahami workflow klasifikasi dengan menggunakan metode Naive Bayes, kita akan coba menganalisis data dari United States Congressional Voting tahun 1984. Data berisi informasi tentang hasil voting atau dukungan dari masing-masing anggota kongres dengan affiliasi partai yang berbeda (Republican/Democrat) terhadap berbagai isu atau kebijakan negara.

**Business Question: Lakukan klasifikasi apakah seseorang cenderung berafiliasi dengan partai `Republican` atau `Democrat`.**

### Read Data

Pembacaan data dilakukan, kemudian disimpan dengan variabel `party`

```{r party, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
# chunk untuk menyimpan semua variabel yang digunakan pada party
# baca data

#setwd("D:/ALGORITMA/DSS Project #2/LearnR-C2")
party <- read.csv("data_input/votes.txt", header = F, stringsAsFactors = T)

# mengubah nama kolom
names(party) <- c("party",
                  "hcapped_infants",
                  "watercost_sharing",
                  "adoption_budget_reso",
                  "physfee_freeze",
                  "elsalvador_aid",
                  "religious_grps",
                  "antisatellite_ban",
                  "nicaraguan_contras",
                  "mxmissile",
                  "immigration",
                  "synfuels_cutback",
                  "education_funding",
                  "superfundright_sue",
                  "crime",
                  "dutyfree_exps",
                  "expadmin_southafr"
                  )

# splitting data
RNGkind(sample.kind = "Rounding")
set.seed(100)
index <- sample(x = nrow(party), size= nrow(party)*0.75)
party_train <- party[index,] # subsetting data berdasarkan index data yang ada di variabel index 
party_test <- party[-index,]

# modeling
model_party <- naiveBayes(party ~ ., data = party_train, laplace = 1)
# prediksi kelas target
party_predClass <- predict(object = model_party, newdata = party_test, type = "class")
# ambil hasil prediksi probability
pred_partyProb <- predict(object = model_party, newdata = party_test, type = "raw")
# membuat data_roc
data_roc <- data.frame(pred_proba = pred_partyProb[, "democrat"],
                       actual = ifelse(party_test$party == "democrat", 1, 0))
# buat objek prediction
roc_pred <- prediction(predictions = data_roc$pred_proba, 
                       labels = data_roc$actual)
```
  
  
```{r}
head(party)
```

Keterangan:

* y = yes (setuju)
* n = no (tidak setuju)
* ? = tidak vote

### Cross-Validation

Lakukan splitting data menjadi data training dan data testing, dengan proporsi data train sebesar 75%. Kemudian simpan data train pada variabel `party_train` dan data test pada variabel `party_test`

```{r splitting, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "party"}
# index <- sample(x = ..., size= ...)
# party_train <- ...
# party_test <- ...

```

Kemudian lakukan pengecekan pada proporsi kelas target pada data training:

```{r prop, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "party"}
# Cek proporsi kelas target pada data training

```
<div id="prop-hint">
**Hint:** Gunakan function `prop.table()`
</div>

```{r question-a, echo=FALSE}
question("Berapa persen proporsi kelas target untuk Democrat? (Dib)", type = "single",
correct = "Yap, benar!", incorrect = "Jawaban Anda masih kurang tepat", allow_retry = TRUE,
random_answer_order = FALSE,
answer("40%"),
answer("60%", correct = TRUE),
answer("50%"),
answer("65%"))
```

```{r question-b, echo=FALSE}
question("Dengan toleransi rasio kelas target antara data train dan data test adalah 15%, apakah proporsi untuk masing-masing kelas target sudah seimbang atau tidak?", type = "single",
correct = "Yaps benar!", incorrect = "Jawaban Anda masih kurang tepat", allow_retry = TRUE,
random_answer_order = FALSE,
answer("Tidak seimbang"),
answer("Seimbang", correct = TRUE))
```

### Model Fitting

Lakukan training model menggunakan argumen `naiveBayes()` dengan `party` sebagai target dan variabel lainnya sebagai prediktor. Lalu simpan dengan nama `model_party`. Untuk menangani _data scarcity_, tambahankan parameter `laplace = 1`

```{r train, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "party"}
# melakukan training model

```
<div id="train-hint">
**Hint:** Struktur _code_ untuk training model: `model_party <- naiveBayes(formula = ... , data = ..., laplace = ...`)
</div>

Lakukan interpretasi masing-masing prediktor dari hasil perhitungan peluang dependennya dengan variabel target. Untuk itu tampilkan `model_party` yang sudah dibuat sebelumnya.
```{r model, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "party"}

```


```{r question-c, echo=FALSE}
question("Berdasarkan output dari model, manakah pernyataan berikut yang benar? ",
correct = "Yaps benar!", incorrect = "Jawaban Anda masih kurang tepat, cek lagi outputnya!", allow_retry = TRUE,
random_answer_order = FALSE,
answer("Proporsi dari peserta kongres yang setuju terhadap isu crime dan dia mendukung democrat ada sebanyak 0.318 atau 31.8%", correct = TRUE),
answer("Proporsi dari peserta kongres yang tidak setuju terhadap isu dutyfree dan mendukung republican sebanyak 0.843 atau 84%
", correct = TRUE),
answer("Proporsi dari peserta kongres yang tidak memilih terhadap isu immigration dan dia mendukung democrat ada sebanyak 0.25 atau 25%"))
```

### Model Prediction

Lakukan prediksi kelas dari data test dengan function `predict() `, lalu masukan ke dalam variabel `party_predClass`. Berikut keterangan parameter `type` dalam model Naive Bayes:

- `type = "raw"` mengembalikan nilai peluang untuk masing-masing kelas
- `type = "class"` mengembalikan label kelasnya (_default threshold_ 0.5)

```{r pred, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "party"}
# prediksi kelas target

```

<div id="pred-hint">
**Hint:** Struktur _code_ untuk prediksi kelas: `party_predClass <- predict(object = ..., newdata = ..., type = "...")`
</div>

### Model Evaluation

Lakukan evaluasi model dengan menampilkan confusion matrix.

```{r eval_model, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "party"}
# evaluasi model dengan Confusion Matrix

```

```{r question-d, echo=FALSE}
question("Dikarenakan data yang digunakan dianggap seimbang (balance) dan setiap kelas dianggap penting, maka metrics manakah yang diunggulkan dalam evaluasi model? ", type = "single",
correct = "Yaps benar!", incorrect = "Cek lagi outputnya!", allow_retry = TRUE,
random_answer_order = FALSE,
answer("Pos Pred Value/Precision"),
answer("Specificity"),
answer("Sensitivity"),
answer("Accuracy", correct = TRUE))
```

```{r question-e, echo=FALSE}
question("Berapakah nilai akurasi yang diperoleh dari model? ",
correct = "Yaps benar!", incorrect = "Cek lagi outputnya!", allow_retry = TRUE,
random_answer_order = FALSE,
answer("87%", correct = TRUE),
answer("80%"),
answer("72%"),
answer("92%")
)
```

Berdasarkan metrics akurasi, model dengan Naive Bayes yang diperoleh dapat dikatakan sudah cukup baik dalam melakukan klasifikasi dan prediksi pada data. Namun catatan penting yang perlu diketahui, ketika data yang kita miliki imbalance dan kita ingin melihat seberapa baik model dalam membedakan kedua kelas (kelas positif & kelas negatif) dengan baik, maka dibutuhkan metrics lain yaitu ROC (Receiver-Operating Curve) dan AUC (Area Under Curve).

### Receiver-Operating Curve (ROC)

ROC adalah kurva yang menghubungkan antara _True Positive Rate_ dengan _False Positive Rate_. Model yang baik idealnya memiliki _True Positive Rate_ yang tinggi dan _False Positive Rate_ yang rendah.

Mari kita buat kurva ROC dari model `model_party`. Untuk itu, langkah pertama adalah melakukan prediksi kembali terhadap data test, namun kali ini kita mengambil nilai peluang untuk masing-masing kelas. Simpan hasil prediksi probabilitas dengan nama `pred_partyProb`

```{r pred_target, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "party"}
# prediksi probabilitas

```

Untuk mempermudah, kita siapkan data frame untuk ROC dengan asumsi kelas positifnya adalah "democrat".

```{r}
data_roc <- data.frame(pred_proba = pred_partyProb[, "democrat"],
                       actual = ifelse(party_test$party == "democrat", 1, 0))
head(data_roc)
```

Selanjutnya buat kurva ROC dengan menyiapkan objek `prediction()`:

```{r roc, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "party"}
# buat objek prediction
# roc_pred <- prediction(predictions = ..., labels = ...)

# buat plot dari objek prediction
# plot(performance(prediction.obj = ..., measure = "tpr", x.measure = "fpr"))
```

<div id="roc-hint">
**Hint:** Berikut keterangan untuk parameter pada function `prediction()`:
- predictions → nilai dari prediksi probabilitas (`pred_proba`) pada `data_roc`
- labels → nilai `actual` dari `data_roc`
</div>

Berikut output yang diharapkan:

```{r echo=FALSE, message=FALSE}
# buat objek prediction
roc_pred <- prediction(predictions = data_roc$pred_proba, 
                       labels = data_roc$actual)

# buat plot dari objek prediction
plot(performance(prediction.obj = roc_pred, measure = "tpr", x.measure = "fpr"))
```

### Area Under ROC Curve (AUC)

AUC menunjukkan luas area di bawah kurva ROC. Semakin nilai AUC mendekati 1, maka semakin bagus performa modelnya. Gunakan function `performance()` untuk mendapatkan nilai AUC.

```{r auc, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "party"}
# menghitung nilai AUC
# auc_value <- performance(prediction.obj = ..., measure = ...)

# menampilkan nilai AUC
# auc_value@y.values 

```

```{r question-f, echo=FALSE}
question("Berdasarkan output yang dihasilkan, manakah pernyataan berikut yang benar?",
correct = "Yaps benar!", incorrect = "Jawaban Anda masih kurang tepat, cek lagi outputnya!", allow_retry = TRUE,
random_answer_order = FALSE,
answer("Nilai AUC yang dihasilkan sebesar 0.969, artinya model mampu mengklasifikasikan kelas positif dan kelas negatif dengan baik.", correct = TRUE),
answer("Nilai AUC yang dihasilkan sebesar 0.969, artinya model tidak mampu mengklasifikasikan kelas positif dan kelas negatif dengan baik."),
answer("Nilai AUC yang dihasilkan sebesar 0.969, artinya model hanya baik memprediksi salah satu kelas saja."))
```


## Bab 2 : Text Mining

Text Mining adalah salah satu metode analisis data untuk mendapatkan informasi dan pola-pola yang berguna dari sekumpulan dokumen. Maka sumber data yang digunakan pada text mining adalah kumpulan teks yang memiliki format yang tidak terstruktur. Salah satu algoritma yang sering digunakan untuk kasus klasifikasi dari data teks adalah Naive Bayes. Hal ini dikarenakan waktu komputasi cukup cepat untuk prediktor kata yang banyak. 

Secara umum, workflow pada text mining adalah:

1. Read Data
2. Data Wrangling
3. Exploratory Data Analysis
4. Data Pre-processing:
   a. Mengubah teks menjadi corpus
   b. _Corpus cleansing_
   c. Mengubah corpus menjadi Document-Term Matrix
5. Cross-Validation
6. Further Data Pre-processing:
   a. Feature Selection dengan `findFreqTerms()`
   b. Bernoulli Converter
7. Pembuatan Model
8. Prediksi Data Test
9. Model Evaluation

### Study Case: Spam Classifier

Sebagai latihan untuk memahami workflow klasifikasi pada data teks menggunakan metode Naive Bayes, kita akan menganalisis data sms yang telah memiliki label spam atau ham.

**Business Question:** Berdasarkan kata-kata pada SMS, kita ingin melakukan klasifikasi apakah suatu SMS termasuk spam atau bukan (ham). Kelas positif atau kelas yang ingin difokuskan pada _case_ ini adalah `spam`

### Read Data

Pembacaan data dilakukan, kemudian disimpan dengan variabel `sms_raw`

```{r sms, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
# chunk untuk menyimpan semua variabel yang digunakan pada sms_raw
# baca data
# setwd("D:/ALGORITMA/DSS Project #2/LearnR-C2")
sms_raw <- read.csv("data_input/spam.csv",
                    stringsAsFactors = FALSE,
                    encoding = "UTF-8")

# wrangling
sms <- sms_raw %>% 
  mutate(v1 = as.factor(v1)) %>% 
  select(- c(X , X.1 , X.2)) %>% 
  rename(label = v1, text = v2) 

# ubah format menjadi corpus
sms_corpus <- VCorpus(VectorSource(sms$text))

# case-folding: mengubah semua text menjadi lowercase
sms_corpus_clean <- tm_map(sms_corpus, content_transformer(tolower))

# remove numbers: menghapus angka
sms_corpus_clean <- tm_map(sms_corpus_clean, removeNumbers)

# remove stopwords: menghapus kata yang sering muncul di corpus dan biasanya tidak meaningful
sms_corpus_clean <- tm_map(sms_corpus_clean, removeWords, stopwords("english"))

# remove punctuation
sms_corpus_clean <- tm_map(sms_corpus_clean, removePunctuation)

# stemming: mengembalikan kata dasar
sms_corpus_clean <- tm_map(sms_corpus_clean, stemDocument)

# remove white space
sms_corpus_clean <- tm_map(sms_corpus_clean, stripWhitespace)

# ubah menjadi Document Term Matrix
sms_dtm <- DocumentTermMatrix(sms_corpus_clean)

# melakukan splitting berdasarkan sms_dtm
RNGkind(sample.kind = "Rounding")
set.seed(100)

intrain <- sample(nrow(sms_dtm), nrow(sms_dtm)*0.75)
# train-test splitting
sms_train <- sms_dtm[intrain,]
sms_test <- sms_dtm[-intrain,]

# ambil label target untuk data train
label_train <- sms[intrain, "label"]
# ambil label target untuk data test
label_test <- sms[-intrain, "label"]

# mengambil kata yang sering muncul
sms_freq <- findFreqTerms(sms_train, lowfreq = 20)
# subsetting sms_train terhadap kata `sms_freq` 
sms_train <- sms_train[, sms_freq]

# function bernoulli
bernoulli_conv <- function(x){
  # parameter ifelse: kondisi, TRUE, FALSE
  x <- as.factor(ifelse(x > 0, 1, 0)) 
  return(x)
}

# bernoulli converter
sms_train_bn <- apply(X = sms_train, MARGIN = 2, FUN = bernoulli_conv)
sms_test_bn <- apply(X = sms_test, MARGIN = 2, FUN = bernoulli_conv)

# melakukan training model
model_spam <- naiveBayes(x = sms_train_bn, # variabel prediktor
                         y = label_train, # variabel target
                         laplace = 1)

# melakukan prediksi pada data test
sms_predClass <- predict(object= model_spam, newdata = sms_test_bn, type = "class") 
head(sms_predClass) 

# evaluasi model dengan Confusion Matrix
confusionMatrix(as.factor(sms_predClass), reference = label_test, positive = "spam")

# prediksi probabilitas
sms_pred_prob <- predict(object = model_spam, newdata = sms_test_bn, type = "raw")

# simpan ke bentuk data frame
data_sms_roc <- data.frame(pred_prob_sms = sms_pred_prob[, "spam"],
                           actual = label_test)

# hasil object `prediction()`
sms_roc <- prediction(predictions = data_sms_roc$pred_prob_sms, labels = data_sms_roc$actual)

# menghitung nilai AUC
sms_value <- performance(prediction.obj = sms_roc, measure = "auc")

```


```{r}
head(sms_raw)
```


Deskripsi data :

 - `v1`: status SMS (spam/ham)
 - `v2`: teks SMS 

### Data Wrangling

Berdasarkan inspeksi data, lakukan beberapa langkah berikut untuk merapikan data mentah sehingga dapat dibaca dengan mudah. 

1. Ubah kolom `v1` menjadi bentuk factor
2. Hapus 3 kolom terakhir yang tidak memiliki nilai dan informasi
2. Gantilah nama kolom pertama `v1` menjadi `label` dan kolom kedua`v2` menjadi `text`

Simpan dataframe yang sudah dirapikan dengan nama `sms`.

```{r wrangling, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "sms"}
# data wrangling

```

<div id="wrangling-hint">
**Hint:** Solusi code yang bisa digunakan:
`sms <- sms_raw %>% 
  mutate(v1 = ...) %>% # gunakan function as.factor() untuk mengubah v1
  select(- c( ..... )) %>% # isi dengan nama kolom yang ingin dihapus
  rename(label = ..., text = ...) #rename kolom sesuai instruksi
</div>

Hasil akhir dari format tabel yang diharapkan adalah sebagai berikut:

```{r echo=FALSE}
sms <- sms_raw %>% 
  mutate(v1 = as.factor(v1)) %>% 
  select(- c(X , X.1 , X.2)) %>% 
  rename(label = v1, text = v2) 
head(sms)
```


### Exploratory Data Analysis (EDA)

Silahkan ambil 5 sampel teks yang termasuk spam menggunakan function `filter`. Kemudian amati kata-kata apa saja yang dapat menjadi indikator (prediktor) bahwa suatu text adalah spam?

```{r eda, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "sms"}
# tampilkan 5 sampel teks yang termasuk spam

```

```{r question-g, echo=FALSE}
question("Berdasarkan output yang dihasilkan, manakah dari kata-kata berikut yang berpotensial mengindikasi bahwa suatu teks adalah spam",
correct = "Yaps benar!", incorrect = "Jawaban Anda masih kurang tepat. Jawaban bisa lebih dari satu!", allow_retry = TRUE,
random_answer_order = FALSE,
answer("FREE", correct = TRUE),
answer("PRIZE", correct = TRUE),
answer("AVALAIBLE"))
```

### Data Preprocessing

Tahap selanjutnya adalah data preprocessing, yang merupakan salah satu tahapan persiapan dan pembersihan data agar bisa digunakan untuk pengolahan selanjutnya..

#### Text to Corpus

Sebelum pembersihan data lebih lanjut, teks perlu diubah menjadi format corpus. Corpus adalah kumpulan dari dokumen. Pada kasus ini, satu dokumen ekuivalen dengan satu observasi SMS. 

Ubahlah teks menjadi corpus dengan menggunakan function `VCorpus()`, lalu simpan pada variabel `sms_corpus` 


```{r corpus, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "sms"}
# ubah format menjadi corpus

```

#### Text Cleansing

Lakukan pembersihan data menggunakan _function_ `tm_map` berdasarakan langkah-langkah berikut. Lalu simpan setiap perubahan pada variabel `sms_corpus_clean`

- Mengubah semua huruf kapital menjadi huruf kecil agar menyamakan format pada teks. 

```{r lower, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "sms"}
# case-folding: mengubah semua text menjadi lowercase

```

- Menghapus angka dikarenakan pada umumnya angka tidak mengandung arti yang signifikan

```{r numbers, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "sms"}
# remove numbers: menghapus angka

```

- Menghilangkan kata-kata umum yang kurang bermakna yang biasanya muncul dalam jumlah besar (stopwords)

```{r stopwords, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "sms"}
# remove stopwords: menghapus kata umum yang kurang bermakna

```

- Menghilangkan tanda baca (_punctuation_). Tanda baca yang dihilangkan: ! ' # S % & ' ( ) * + , - . / : ; < = > ? @ [ / ] ^ _ { | } ~


```{r punc, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "sms"}
# remove punctuation: menghapus tanda baca

```

- Menghapus kata-kata imbuhan yang kurang bermakna atau pemotongan kata menjadi kata dasarnya dengan _function_ . Misalnya _'walking'_, _'walked'_, _'walks'_ menjadi _'walk'_. Proses ini dilakukan untuk menyeragamkan setiap kata menjadi bentuk baku agar prediktor tidak berulang.

```{r stem, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "sms"}
# stemming: mengembalikan kata dasar

```

- Menghapus spasi berlebih (_white space_). Proses ini penting dilakukan karena pada tahap selanjutnya yaitu _tokenizing_ dan pembuatan document-term-matrix akan mengambil kata perkata dengan separator spasi "_"

```{r white, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "sms"}
# remove white space: menghapus spasi berlebih

```

### Document-Term Matrix (DTM)

Sampai di tahap ini, data kita masih berupa text. Maka untuk keperluan modeling pada klasifikasi, kita perlu melakukan transformasi data text menjadi Document-Term Matrix (DTM) melalui proses tokenization. Tokenization adalah proses memecah satu kalimat menjadi beberapa term (bisa berupa 1 kata, pasangan kata, dll). Dalam DTM, 1 kata akan menjadi 1 prediktor dengan nilai berupa frekuensi kemunculan kata tersebut dalam sebuah dokumen.

Ubahlah text menjadi Document-Term Matrix dan simpan pada variabel `sms_dtm`. Kemudian lakukan inspeksi pada variabel tersebut dengan function `inspect`

```{r dtm, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "sms"}
# ubah menjadi Document Term Matrix

# inspect sms_dtm

```


```{r question-h, echo=FALSE}
question("Berdasarkan hasil inspeksi dari hasil konversi ke Document-Term Matrix, berapakah kata unik yang muncul di seluruh SMS?", type = "single",
correct = "Yaps benar!", incorrect = "Jawaban Anda masih kurang tepat. Perhatikan output kembali!", allow_retry = TRUE,
random_answer_order = FALSE,
answer("5572"),
answer("6474", correct = TRUE),
answer("42354"),
answer("36030774"))
```


```{r question-i, echo=FALSE}
question("Berdasarkan hasil inspeksi dari hasil konversi ke Document-Term Matrix, berapakah nilai 0 yang muncul pada matrix di seluruh SMS?", type = "single",
correct = "Yaps benar!", incorrect = "Jawaban Anda masih kurang tepat. Perhatikan output kembali!", allow_retry = TRUE,
random_answer_order = FALSE,
answer("5572"),
answer("6474"),
answer("42354"),
answer("36030774", correct = TRUE))
```

### Cross-Validation

Langkah selanjutnya adalah splitting data menjadi `sms_train` dan `sms_test` dengan dengan proporsi data train sebesar 75%. 

```{r cv, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "sms"}
# melakukan splitting data train dan data test


```

Kemudian siapkan juga label untuk variabel target dari masing-masing data train dan data test. Simpan dengan nama variabel `label_train` dan `label_test`.

```{r label, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "sms"}
# ambil label target untuk data train 

# ambil label target untuk data test

```

### Further Data Preprocessing

#### Remove Infrequent Words

Langkah selanjutnya adalah menghapus kata yang jarang muncul. Tahap ini dilakukan untuk mengurangi _noise_ dan menyeleksi _features_ / prediktor berdasarkan kata-kata yang sering muncul saja. 

Gunakan function `findFreqTerms()` untuk mengambil kata yang sering muncul pada `sms_train` minimal sebanyak 20 kali. Lalu simpan dengan nama variabel `sms_freq`. 

```{r freq, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "sms"}
# mengambil kata yang sering muncul

```

Lakukan subsetting `sms_train` hanya untuk kata-kata yang muncul di `sms_freq`

```{r subset, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "sms"}
# subsetting sms_train terhadap kata `sms_freq` 

# inspect sms_train

```

#### Bernoulli Converter

Nilai pada matrix `sms_train` masih berupa frekuensi. Untuk perhitungan peluang, frekuensi akan diubah menjadi hanya kondisi muncul (1) atau tidak (0). Salah satu caranya dengan menggunakan **Bernoulli Converter**.

- Jika frekuensi >= 1, maka bernilai 1 (muncul)
- Jika frekuensi == 0, maka bernilai 0 (tidak muncul)

Untuk itu, selanjutnya sudah dibuat sebuah fungsi dengan nama `bernoulli_conv`

```{r}
bernoulli_conv <- function(x){
  # parameter ifelse: kondisi, TRUE, FALSE
  x <- as.factor(ifelse(x > 0, 1, 0)) 
  return(x)
}

```

Selanjutnya, terapkan `bernoulli_conv` ke `sms_train` dan `sms_test`. Simpan dengan nama `sms_train_bn`.

```{r bernoull, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "sms"}
# aplikasi bernoulli_conv pada sms_train
# sms_train_bn <- apply(X = ..., MARGIN = ..., FUN = ...)

# aplikasi bernoulli_conv pada sms_test
# sms_test_bn <- apply(X = ..., MARGIN = ..., FUN = ...)

```

Output yang diharapkan ketika melakukan subset baris dan kolom 6 sampai 10 adalah:  
```{r}
sms_train_bn[6:10, 6:10]
```

Nilai matrix yang dihasilkan sudah berupa `binary` yaitu 0 (tidak muncul) dan 1 (muncul).

### Model Fitting

Persiapan data sudah selesai, selanjutnya  buatlah model Naive Bayes dengan `label_train` sebagai target dan variabel `sms_train_bn` sebagai prediktor. Lalu simpan dengan nama `model_spam`. Untuk menangani _data scarcity_, tambahankan parameter `laplace = 1`

```{r train-sms, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "sms"}
# melakukan training model

```

### Model Prediction

Lakukan prediksi kelas target pada `sms_test_bn` berdasarkan model yang sudah dibangun. Simpan ke objek `sms_pred_class`.

```{r test-sms, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "sms"}
# melakukan prediksi pada data test

```

### Model Evaluation

Langkah selanjutnya adalah evaluasi model, kali ini kita akan mencoba menggunakan Confusion Matrix dan ROC/AUC.

#### Confusion Matrix

Lakukan evaluasi `model_spam` terhadap hasil prediksi data test menggunakan confusion matrix. Ingat bahwa target yang menjadi kelas positif adalah `spam`

```{r eval-sms, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "sms"}
# evaluasi model dengan Confusion Matrix

```

```{r question-j, echo=FALSE}
question("Apabila kita tidak ingin sms yang penting (ham) masuk ke dalam spam, maka metrics mana yang kita perhatikan?", type = "single",
correct = "Yaps benar!", incorrect = "Jawaban Anda masih kurang tepat.", allow_retry = TRUE,
random_answer_order = FALSE,
answer("Precision/Pos Pred Value karena kita ingin meminimalisir False Positive", correct = TRUE),
answer("Precision/Pos Pred Value karena kita ingin meminimalisir False Negative"),
answer("Recall/Sensitivity karena kita ingin meminimalisir False Positive"),
answer("Recall/Sensitivity karena kita ingin meminimalisir False Negative"))
```

#### ROC and AUC

Untuk meninjau ROC dan AUC, kita perlu mempersiapkan hasil prediksi berupa probability dari `sms_test_bn`, simpan ke objek dengan nama `sms_pred_prob`:

```{r prob-sms, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "sms"}
# prediksi probabilitas

```

Untuk mempermudah, kita siapkan data frame untuk ROC yang disimpan ke objek dengan nama `data_sms_roc`:

```{r}
data_sms_roc <- data.frame(pred_prob_sms = sms_pred_prob[, "spam"],
                           actual = label_test)
```

Selanjutnya buat kurva ROC. Simpan hasil object `prediction()` dengan nama `sms_roc`:

```{r roc_sms, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "sms"}
# buat objek prediction

# buat plot dari objek prediction

```

Berikut output yang diharapkan:

```{r echo=FALSE, message=FALSE}
# buat objek prediction
sms_roc <- prediction(predictions = data_sms_roc$pred_prob_sms, labels = data_sms_roc$actual) 

# buat plot dari objek prediction
plot(performance(prediction.obj = sms_roc, measure = "tpr", x.measure = "fpr"))
```

Hitung nilai AUC dengan menggunakan function `performance()`

```{r auc_sms, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "sms"}
# menghitung nilai AUC

```

```{r question-k, echo=FALSE}
question("Berdasarkan output yang dihasilkan, manakah pernyataan berikut yang benar?",
correct = "Yaps benar!", incorrect = "Jawaban Anda masih kurang tepat, cek lagi outputnya!", allow_retry = TRUE,
random_answer_order = FALSE,
answer("Nilai AUC yang dihasilkan sebesar 0.97, artinya model mampu mengklasifikasikan kelas positif dan kelas negatif dengan baik.", correct = TRUE),
answer("Nilai AUC yang dihasilkan sebesar 0.97, artinya model tidak mampu mengklasifikasikan kelas positif dan kelas negatif dengan baik."),
answer("Nilai AUC yang dihasilkan sebesar 0.97, artinya model hanya baik memprediksi salah satu kelas saja."))
```

## Bab 3 : Decision Tree

Decision Tree merupakan _tree-based model_ yang cukup sederhana dengan performa yang _robust_ dan _powerful_ untuk melakukan prediksi. Decision Tree menghasilkan visualisasi berupa pohon keputusan yang dapat diinterpretasi dengan mudah. Karakteristik lainnya pada Decision Tree adalah variabel prediktor diasumsikan saling dependent. Sehingga algoritma ini dapat mampu mengatasi _multicollinearity_ dan _outlier_. Kemudian Desicion Tree dapat melakukan prediksi menggunakan prediktor numerik maupun kategorik.

Berikut komponen dalam Desicion Tree:

- **Root Node**: Percabangan pertama dalam menentukan nilai target, biasa disebut sebagai predictor utama.
- **Interior Node**: Percabangan selanjutnya yang menggunakan predictor lain apabila root node tidak cukup dalam menentukan target.
- **Terminal/Leaf Node**: Keputusan akhir berupa nilai target yang diprediksi.

Dalam memilih predictor pada setiap percabangannya, Decision Tree akan memilih predictor yang sebisa mungkin meng-homogen-kan target variable pada leaf node nya. Tingkat kehomogenan ini dapat dikuantifikasi menggunakan **Entropy** dan **Information Gain**.

### Entropy and Information Gain

Entropy adalah ukuran ketidakteraturan (measure of disorder) dari sebuah kelompok data. Nilai entropy berkisar antara 0 sampai 1. Entropy bernilai 1 artinya tidak ada kelas yang dominan (proporsi seimbang, 50:50), sedangkan entropy bernilai 0, artinyasalah satu kelas sangat dominan (proporsi 100:0).

Kelompok data yang diharapkan setelah dilakukan percabangan adalah kelompok yang memiliki entropy rendah. Kemudian untuk predictor yang dipilih adalah predictor yang menghasilkan penurunan entropy paling besar, karena berarti membuat data setelah pemisahan semakin homogen. Perubahan entropy inilah yang disebut Information Gain.

### Study Case: Diabetes

**Business Question:** Sebagai seorang konsultan kesehatan di sebuah rumah sakit, kita diminta untuk membuat _rules_ dari hasil tes diagnosis dan riwayat penyakit diabetes dari 768 pasien. Dalam kasus ini, kita akan mengaplikasikan Decision Tree agar rules dapat disajikan dalam bentuk visualisasi yang mudah diinterpretasi.

- kelas positif: diabetes (pos)
- kelas negatif: sehat (neg)

### Read Data

Pembacaan data dilakukan, kemudian disimpan dengan variabel `diab`

```{r data_diab, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
# chunk untuk menyimpan semua variabel yang digunakan pada party
# baca data
# setwd("D:/ALGORITMA/DSS Project #2/LearnR-C2")
diab <- read.csv("data_input/diabetes.csv", stringsAsFactors = T)

#splitting data
RNGkind(sample.kind = "Rounding")
set.seed(100)
intrain <- initial_split(data = diab, prop = 0.8, strata = "diabetes")
diab_train <- training(intrain) 
diab_test <- testing(intrain)

# downsampling
diab_train_down <- downSample(x = diab_train[, -9], # menghilangkan kolom diabetes yang berada pada urutan ke 9
                              y = diab_train$diabetes,
                              yname = "diabetes") # nama kolom target variabel

# melakukan training model
diabetes_tree <- ctree(formula = diabetes~., data = diab_train_down)

# prediksi kelas di data test
diab_pred_class <- predict(object = diabetes_tree, newdata = diab_test, type = "response")

# confusion matrix data test
confusionMatrix(data = as.factor(diab_pred_class),
                reference = diab_test$diabetes, positive = "pos") 

# prediksi kelas di data train
diab_pred_class_train <- predict(object = diabetes_tree, newdata = diab_train_down, type = "response")

# confusion matrix data train
confusionMatrix(data = as.factor(diab_pred_class_train),
                reference = diab_train_down$diabetes, positive = "pos") 

# tuning model
diab_model_new <- ctree(formula = diabetes~., data = diab_train_down, 
                        control = ctree_control(mincriterion = 0.07,
                                                minsplit = 35,
                                                minbucket = 10))
                        
# prediksi `kelas` data test
diabtest_new <- predict(object = diab_model_new, newdata = diab_test, type = "response")

# confusion matrix data test
confusionMatrix(data = diabtest_new, reference = diab_test$diabetes, positive = "pos")

# prediksi `kelas` data train
diabtrain_new <- predict(object = diab_model_new, newdata = diab_train, type = "response")

# confusion matrix data train
confusionMatrix(data = diabtrain_new, reference = diab_train$diabetes, positive = "pos")

```
  
  
```{r}
head(diab)
```

Deskripsi data:

- `pregnant`: jumlah berapa kali hamil
- `glucose`: konsentrasi glukosa plasma (glucose tolerance test)
- `pressure`: tekanan darah diastolik (mm Hg)
- `triceps`: ketebalan lipatan kulit trisep (mm)
- `insulin`: insulin serum-2 jam (mu U/ml)
- `mass`: indeks massa tubuh (berat dalam kg/(tinggi dalam m)^2)
- `pedigree`: silsilah diabetes
- `age`: umur (tahun)
- `diabetes`: hasil cek diabetes

### Cross-Validation

Dikarenakan tipe data sudah sesuai, tidak ada missing value, dan data sudah dianggap bersih, maka langkah selanjutnya adalah melakukan split data `diab` menjadi `diab_train` dan `diab_test` dengan proporsi 80:20.

Untuk menyamakan strata/proporsi untuk kedua target variabel pada data train dan data test ketika melakukan splitting, gunakan _function_ `initial_split()` dari _package_ `rsample`.

```{r split_diab, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "data_diab"}
# splitting data train dan data test
# intrain <- initial_split(data = ..., prop = ..., strata = "...")
# diab_train <- training(...) 
# diab_test <- testing(...)

```

Setelah melakukan splitting, maka seharusnya proporsi kelas di data training adalah sebagai berikut:

```{r}
prop.table(table(diab_train$diabetes))
```

Berdasarkan output yang dihasilkan, proporsi `diab_train` sebenarnya masih bisa dianggap balance. Namun kita bisa coba membuatnya lebih balance lagi sehingga proporsinya 50:50. Teknik yang bisa digunakan adalah:

- **Upsample** : menambahkan observasi minoritas hingga seimbang dengan mayoritas, dengan menduplikat data dari observasi minoritas. 
- **Downsample** : mengurangi observasi mayoritas hingga seimbang dengan yang minoritas.  

Pada kasus ini karena data yang kita miliki cukup banyak, maka kita bisa melakukan downsampling dengan menggunakan fungsi dari _library_ `caret` yaitu _function_ `downSample()`. Simpan hasil penyeimbangan kelas target pada variabel `diab_train_down`

```{r down_diab, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "data_diab"}
# diab_train_down <- downSample(x = ..., y = ..., yname = ...) 

```

<div id="down_diab-hint">
**Hint:** Berikut keterangan untuk parameter pada function `downSample()`:
- x → mengambil variabel prediktor pada `diab_train` 
- y → mengambil variabel target pada `diab_train`
- y → nama kolom variabel target 
</div>

### Model Fitting

Lakukan training model pada data `diab_train_down`dengan Decision Tree menggunakan argumen `ctree()`. Gunakan kolom `diabetes` sebagai variabel target dan kolom lainnya sebagai prediktor. Lalu simpan dengan nama `diabetes_tree`. 

Kemudian tampilkan stuktur tree dengan memanggil model nya 
```{r train_diab, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "data_diab"}
# melakukan training model

# print struktur pohon

```

Berikut output yang diharapkan: 
```{r}
diabetes_tree
```

```{r question-l, echo=FALSE}
question("Berdasarkan struktur tree dari model, ketika ada seorang pasien dengan konsentrasi glukosa plasma (glucose) sebesar 130 dan indeks massa tubuh (mass) sebesar 33.6, maka pada kelas mana model akan mengklasifikasikan pasien tersebut?", type = "single",
correct = "Yaps benar!", incorrect = "Jawaban Anda masih kurang tepat. Perhatikan output kembali!", allow_retry = TRUE,
random_answer_order = FALSE,
answer("Positif Diabetes", correct = TRUE),
answer("Negatif Diabetes"))
```

```{r question-m, echo=FALSE}
question("Berdasarkan struktur tree, berapakah persentase kesalahan prediksi  yang dihasilkan model dalam mengklasifikasikan pasien dengan konsentrasi glukosa plasma (glucose) <= 114 dan pernah hamil (pregnant) <= 6?", type = "single",
correct = "Yaps benar!", incorrect = "Jawaban Anda masih kurang tepat. Perhatikan output kembali!", allow_retry = TRUE,
random_answer_order = FALSE,
answer("48,6%"),
answer("17.4%", correct = TRUE),
answer("35,6%"), 
answer("24.3%"))
```

### Model Prediction

Lakukan prediksi kelas dari data test dengan function `predict()`, lalu masukan ke dalam variabel `diab_pred_class`

Keterangan parameter `type`:

- `type = "prob"` mengembalikan nilai peluang untuk masing-masing kelas
- `type = "response"` mengembalikan label kelasnya (default threshold 0.5) 

```{r pred_diab, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "data_diab"}
# splitting data train dan data test# prediksi kelas di data test

```

### Model Evaluation

Berdasarkan hasil prediksi di data test, lakukan evaluasi model `diabetes_tree` menggunakan confusion matrix

```{r confusion_diab, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "data_diab"}
# evaluasi model terhadap data test dengan Confusion Matrix

```

```{r question-n, echo=FALSE}
question("Apabila kita tidak ingin pasien yang diabetes namun diklasifikasikan kepada kelas tidak diabetes, maka nilai apa yang ingin kita kurangi atau minimalisir?", type = "single",
correct = "Yaps benar!", incorrect = "Jawaban Anda masih kurang tepat.", allow_retry = TRUE,
random_answer_order = FALSE,
answer("False Positif"),
answer("False Negatif", correct = TRUE))
```

```{r question-o, echo=FALSE}
question("Kemudian metric apakah yang kita perhatikan?", type = "single",
correct = "Yaps benar!", incorrect = "Jawaban Anda masih kurang tepat.", allow_retry = TRUE,
random_answer_order = FALSE,
answer("Accuracy"),
answer("Sensitivity/Recall", correct = TRUE),
answer("Specificity"),
answer("Pos Pred Value/Precision"))
```

Selain melihat _confusion matrix_ untuk data test, ada baiknya kita juga bandingkan dengan _performance model_ di data train  untuk mengetahui fitting dari sebuah model.

Lakukan prediksi kelas pada data train, lalu simpan dengan nama `diab_pred_class_train`

```{r pred_train_diab, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "data_diab"}
# prediksi kelas di data train

```

```{r eval_train_diab, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "data_diab"}
# confusion matrix data train

```

Maka diperoleh nilai evaluasi dari model:
- Recall di data train: 76%
- Recall di data test: 66%

Ketika dibandingkan, performa model `diabetes_tree` cenderung lebih baik pada data train dibandingkan data test. Model ini dikatakan sebagai model yang _overfitting_. Karena performa model belum cukup baik, perlu dilakukan _model tuning_.

### Bias-Variance Tradeoff

Dalam pembuatan model, model berusaha mempelajari pola yang terdapat dalam data sehingga dihasilkan suatu aturan yang dapat memprediksi kelas/nilai target dengan tepat. Untuk masing-masing model machine learning, terdapat karakteristik yang disebut _bias_ dan _variance_.

- _bias_: perbedaan antara hasil prediksi dengan nilai aktual
- _variance_: variasi hasil prediksi yang mungkin muncul pada titik data tertentu

_Bias-Variance Tradeoff_ menyatakan bahwa semakin sederhana suatu model, maka akan semakin tinggi bias dan semakin rendah variancenya; begitupun sebaliknya.

Terdapat 3 kondisi dari model machine learning berdasarkan kemampuanya melakukan prediksi:

* Underfitting: keadaan model yang memiliki bias tinggi dan variance rendah sehingga hasil prediksinya tidak terlalu tepat
* Overfitting: keadaan model yang memiliki variance tinggi dan bias rendah sehingga prediksi di data trainnya amat tepat, namun performanya buruk dalam memprediksi data test 
* Just Right: kondisi model yang memiliki bias dan variance yang saling berimbang (kondisi yang diharapkan). Salah satu tujuan dari model tuning adalah mendapatkan bias-variance trade-off yang optimal.

### Pruning and Tree-size

Kekurangan dari Decision Tree adalah kecenderungannya untuk overfitting. Hal ini terjadi karena Decision tree mampu membagi-bagi data hingga amat detail. Hal ini membuat Decision Tree justru menghafal pola di data train, dan membuat aturan yang terlalu kompleks, bukan mempelajari pola tersebut. Alhasil model menjadi kurang general untuk diaplikasikan ke data yang bukan data train, sehingga cenderung _overfitting_. 

Untuk mengatasinya, Decision Tree perlu tahu kapan ia berhenti membuat cabang sehingga pohon yang dihasilkan tidak terlalu kompleks. Pemotongan/pencegahan cabang pohon itu dinamakan _Pruning_, dimana kita mencegah Decision Tree untuk membuat cabang berdasarkan kriteria tertentu. 

Pruning terbagi menjadi 2 cara:

- Pre-Pruning: memasang parameter sebelum model dihasilkan terlebih dahulu . Metode ini kurang disarankan karena kita belum memiliki informasi tentang parameter apa yang sebaiknya kita atur.

- Post-Pruning: Pruning setelah kita mendapatkan model yang lengkap atau kompleks, lalu menentukan seberapa jauh kita akan memangkas cabang pada Decision Tree.

Parameter pruning:

- mincriterion: Nilai 1-$\alpha$. Saat mincriterion 0.95, P-value harus < 0.05 untuk suatu node dapat membuat cabang. (default: 0.95)
- minsplit: Jumlah minimal observasi di tiap cabang setelah pemisahan. Bila tidak terpenuhi, tidak dilakukan percabangan. (default: 20)
- minbucket: Jumlah minimal observasi di terminal node. Bila tidak terpenuhi, tidak dilakukan percabangan. (default: 7)

Dikarenakan model `diabetes_tree` mengalami overfitting atau pohon yang terlalu kompleks dengan parameter default, maka yang dapat dilakukan adalah meninggikan nilai untuk parameter mincriterion, minsplit dan minbucket.

Buatlah tuning model `diabetes_tree` dengan mengatur parameter _pruning_ dengan nilai mincriterion = 0.07, minsplit = 35, dan minbucket = 10. Lalu simpan pada variabel `diab_model_new`. 

```{r tuning, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "data_diab"}
# diab_model_new <- ctree(formula = ..., data = ..., control = ctree_control())
```

<div id="tuning-hint">
**Hint:** Atur nilai mincriterion, minsplit, dan minbucket pada argumen `ctree_control()`
</div>

Lakukan prediksi kelas dengan model tuning pada data train dan simpan dengan nama `diabtrain_new`

```{r pred_train_tuning, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "data_diab"}
# prediksi `kelas` data train

```

Lakukan prediksi kelas dengan model tuning pada data train test dan simpan dengan nama `diabtrain_new`

```{r pred_test_tuning, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "data_diab"}
# prediksi `kelas` data test

```

Lakukan evaluasi pada model terhadap data train dan data test dengan confusion matrix. 

```{r eval_tuning, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "data_diab"}
# confusion matrix data train

# confusion matrix data test

```

```{r question-p, echo=FALSE}
question("Apabila model masih dianggap optimal jika perbedaan nilai recall dari data train dan data test tidak lebih dari 7%. Maka berdasarkan nilai toleransi tersebut, bagaimanakah kondisi model tuning yang dihasilkan? ", type = "single",
correct = "Yaps benar!", incorrect = "Jawaban Anda masih kurang tepat.", allow_retry = TRUE,
random_answer_order = FALSE,
answer("Underfitting"),
answer("Overfitting"),
answer("Just Right", correct = TRUE))
```

Namun apabila performa model decision tree masih dianggap overfitting, maka yang dapat dilakukan adalah melakukan _hyperparameter tuning_ kembali. Kemudian jika _pruning_ juga masih belum optimal, cara lain untuk meningkatkan performa tree-based model adalah dengan _Ensemble Method_ yang akan dibahas di topik selanjutnya.

---
title: "Classification 2"
output: html_document
---

## Bab 4 : Random Forest

Random Forest adalah salah satu jenis _Ensemble Method_. Ensemble Method adalah metode yg menggabungkan prediksi dari beberapa model menjadi 1 prediksi tunggal. Metode ini bertujuan untuk menangani masalah overfitting. Analogi sederhananya, ketika sebuah keputusan diambil oleh satu orang maka akan rentan bias. Namun bila dilakukan musyawarah, maka keputusannya akan lebih bijak karena merupakan kesepakatan bersama.

Dengan konsep tersebut, Random Forest melakukan prediksi dengan membuat banyak Decision Tree. Masing-masing Decision Tree memiliki karakteristik masing-masing dan tidak saling berhubungan satu sama lain. kemudian dari sekian banyak hasil prediksi tersebut dilakukan voting. Kelas dengan jumlah terbanyak akan menjadi hasil prediksi final. 

Random Forest memanfaatkan konsep bernama Bagging: Bootstrap and Aggregation. Berikut adalah proses yang terjadi:

1. Bootstrap sampling: Membuat data dengan random sampling (with replacement) dari data keseluruhan dan mengizinkan adanya baris yang terduplikat.
2. Dibuat 1 decision tree untuk masing-masing data hasil bootstrap. Digunakan parameter `mtry` untuk memilih banyaknya calon prediktor secara random (_Automatic Feature Selection_)
3. Melakukan prediksi terhadap observasi yang baru untuk setiap Decision Tree.
4. Aggregation: Menghasilkan satu prediksi tunggal untuk memprediksi. Pada kasus klasifikasi dengan _majority voting_, sedangkan pada kasus regresi dengan mengambil rata-rata nilai target

### Study Case: Fitbit

Kita adalah seorang analis dari perusahaan teknologi berbasis machine learning yang mengeluarkan product wearable fitness gadgets. Gadget tersebut menggunakan machine learning untuk secara otomatis mengingatkan penggunanya apabila suatu excercise belum dilakukan secara optimal.

Kita diberikan data rekaman gadgets tersebut beserta label status excercise `classe` sebagai berikut:

- Kelas 1: Tepat sesuai spesifikasi
- Kelas 2: Melempar siku ke depan
- Kelas 3: Mengangkat halter hanya setengah jalan
- Kelas 4: Menurunkan dumbbell hanya setengah jalan
- Kelas 5: Melempar pinggul ke depan

*Bussiness Questions:* Buat model Random Forest yang dapat mengklasifikasikan kelima status tersebut dengan baik.

### Read Data

Pembacaan data dilakukan, kemudian disimpan dengan variabel `fb_raw`

```{r data_fb, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
# chunk untuk menyimpan semua variabel yang digunakan pada party
# baca data
# setwd("D:/ALGORITMA/DSS Project #2/LearnR-C2")
fb_raw <- read.csv("data_input/fitbit.csv", stringsAsFactors = F)
fb_raw <- fb_raw %>% 
  mutate_at(.vars = c("classe", "user_name", "new_window"), .funs = as.factor)
fb_raw %>% select(is.factor)

# feature selection menggunakan nearzerovar
no_var <- nearZeroVar(fb_raw)
fb <- fb_raw[, -no_var]

# splitting data
RNGkind(sample.kind = "Rounding")
set.seed(100)
intrain <- sample(x = nrow(fb), size = nrow(fb)*0.8) 
fb_train <- fb[intrain,] 
fb_test <- fb[-intrain,] 

# read model
fb_forest <- readRDS("fb_forest.RDS")

# prediksi terhadap data test
fb_pred <- predict(object = fb_forest, newdata = fb_test)


```
  
  
```{r}
head(fb_raw)
```

### Data Pre-processing

Kekurangan random forest adalah beban komputasinya yang amat besar dan lama. Hal ini dapat dikurangi dengan menyeleksi prediktor sehingga tidak terlalu banyak. 

Lakukan seleksi fitur dengan menghapus kolom yang memiliki variansi mendekati nol (kurang informatif). Gunakan _function_ `nearZeroVar()` dari package `caret` untuk mendapatkan kolom yang akan dihapus.

```{r zero_fb, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "data_fb"}
# mengambil kolom yang kurang informatif menggunakan nearzerovar
no_var <-
# membuang kolom no_var
fb <- fb_raw[, -no_var]

```

### Cross Validation

Lakukan splitting train test dengan proporsi 80%:20%. Simpan dengan nama `fb_train` dan `fb_test`
```{r split_fb, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "data_fb"}
# splitting data train dan data test


```

### Model Fitting

Kali ini kita akan membuat model random forest dengan mengunakan teknik k-fold cross validation. K-fold cross validation adalah metode cross validation dimana data akan dibagi menjadi $k$ bagian sama banyak. Setiap bagian akan digunakan menjadi data test secara bergantian. Berbeda dengan metode cross validation biasa hanya membagi datanya menjadi `data_train` dan `data_test` secara tetap. Metode ini memberlakukan seluruh data pernah menjadi data train dan data test. Tujuannya supaya bisa mengetahui skema splitting mana yang terbaik. 

Definisikan k-fold cross validation dengan nama variabel `control`, dengan k=5 dan pembuatan set k-fold tersebut dilakukan 3 kali. Gunakan argumen `trainControl` dengan keterangan sebagai berikut:

- `method`: metode dalam melakukan cross validation
- `number`: nilai k dalam k-fold CV
- `repeats`: pengulangan dalam melakukan k-fold CV

```{r fold_fb, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "data_fb"}
# definisikan k-fold validation


```

Kemudian dilakukan pembuatan model random forest dengan _code_ berikut. 

```{r eval=FALSE}
# pembuatan model random forest
fb_forest <- train(formula = classe~., data = fb_train, method = "rf",
                   trainControl = control)
```
Tampilkan summary model dengan memanggil model yang sudah dibuat sebelumnya:
```{r}
# summary model
fb_forest
```

```{r question-q, echo=FALSE}
question("Berdasarkan output summary model random forest, berapakah jumlah prediktor yang digunakan untuk splitting node pada final model", type = "single",
correct = "Yaps benar!", incorrect = "Jawaban Anda masih kurang tepat.", allow_retry = TRUE,
random_answer_order = FALSE,
answer("2"),
answer("31", correct = TRUE),
answer("60"))
```

Selnajutnya kita bisa melihat summary final model dengan menjalankan chunk berikut:
```{r}
fb_forest$finalModel
```

Berdasarkan summary model, kita dapat mengetahui nilai out-of-bag error (OOB) yang dapat dilihat pada keterangan `OOB estimate of  error rate`. Nilai OOB adalah nilai error yg diterima oleh model terhadap _out of bag sample_  (_unseen data_ saat melakukan bootstrap sampling). Dengan mengetahui nilai OOB, maka dapat dihitung nilai akurasi dengan formula berikut:

$$Accuracy  = 100 - OOB $$
```{r question-r, echo=FALSE}
question("Berdasarkan output summary model final, berapakah nilai akurasi yang dihasilkan pada pada data test (out of bag sample)?", type = "single",
correct = "Yaps benar!", incorrect = "Jawaban Anda masih kurang tepat.", allow_retry = TRUE,
random_answer_order = FALSE,
answer("0.08%"),
answer("99.92%", correct = TRUE),
answer("99.99%"))
```

### Interpretation

Random forest adalah model yang tidak dapat diinterpretasikan, namun kita bisa melihat prediktor apa saja yang paling digunakan (penting) dalam pembuatan random forest

```{r}
varImp(fb_forest)
```

```{r question-s, echo=FALSE}
question("Dari output yang terbentuk, variabel mana yang memiliki andil paling tinggi dalam menghasilkan prediksi?", type = "single",
correct = "Yaps benar!", incorrect = "Jawaban Anda masih kurang tepat.", allow_retry = TRUE,
random_answer_order = FALSE,
answer("raw_timestamp_part_1",correct = TRUE),
answer("num_window"),
answer("roll_belt"),
answer("accel_dumbbell_y"))
```

### Prediction 

Lakukan prediksi model `rb_forest` terhadap `fb_test`. Simpan dengan nama variable `fb_pred`

```{r pred_fb, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "data_fb"}
# prediksi terhadap data test

```

### Model Evaluation

Evaluasi model `fb_pred`dengan menggunakan Confusion Matrix. Gunakan kelas positif = 1 

```{r eval_fb, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "data_fb"}
# evaluasi model dengan Confusion Matrix

```

```{r question-t, echo=FALSE}
question("Berdasarkan output, bagaimanakah kondisi model dalam memprediksikan data test? ", type = "single",
correct = "Yaps benar!", incorrect = "Jawaban Anda masih kurang tepat.", allow_retry = TRUE,
random_answer_order = FALSE,
answer("Underfitting"),
answer("Overfitting"),
answer("Just Right", correct = TRUE))
```

#### Don't stop learning!
See yaa :)

