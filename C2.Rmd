---
title: "Classification 2"
author : "Team Algoritma"
date : "February 13, 2022"
output: 
  learnr::tutorial:
  fig.show : 'asis'
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr) # user interface for coding exercise
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
options(tutorial.exercise.timelimit = 90)
# options(scipen = 99)
# Sys.setlocale('LC_ALL','C')

library(dplyr) # data manipulation
library(e1071) # naive bayes model 
library(caret) # classification training
library(ROCR) # roc
library(tm) # text mining
library(SnowballC) # stemmer
library(rsample) # resampling on splitting
library(partykit) # decision tree model 
library(randomForest) # random forest model 
# theme_set(theme_minimal())
```


## Bab 1 : Naive Bayes

Halo _Future Data Scientist!_ Pada _course_ ini kita akan belajar lebih lanjut mengenai metode klasifikasi. Kalau pada _course_ sebelumnya yaitu _Classification 1_ kita sudah mengenal 2 algoritma klasifikasi yang sangat popular yaitu _Logistic Regression_ dan _K-Nearest Neighbor_, kali ini kita diberi kesempatan untuk belajar beberapa algoritma lain yang lebih _advance_ lagi. Namun tidak perlu khawatir, karena secara workflow sama saja seperti pada _Classification 1_, hanya metode saja yang berbeda. Algoritma pertama yang akan kita pelajari adalah _Naive Bayes_. 

Naive Bayes adalah suatu algoritma klasifikasi yang didasari oleh _Bayes' Theorem of Probability_. Faktanya, teorema Bayes amat sering digunakan pada kehidupan sehari-hari. 

### Theory of Probability

Saat kita menghitung peluang 2 atau lebih kejadian terjadi bersamaan, kita dapat menghitungnya dengan 2 cara:

1. _Independent Event_: Peluang kejadian A tidak mempengaruhi peluang kejadian B. 
Contoh: Peluang dadu keluar angka 4 pada lemparan pertama dan peluang keluar angka 6 pada lemparan kedua
Peluang 2 kejadian independen yang dapat terjadi secara bersamaan adalah hasil perkalian peluang masing-masing kejadian tersebut.

$$P(A \cap B) = P(A) \times P(B)$$ 

2. _Dependent Event_: Peluang kejadian A dipengaruhi oleh peluang kejadian B (informasi tentang kejadian B). 
Contoh: Peluang banjir di Jakarta jika diketahui hujan deras di Bogor
Untuk menghitung peluangnya, kita menggunakan _Bayes Theorem_:

$$P(A|B) = \frac{P(B|A) P(A)}{P(B|A) P(A)\ +\  P(B|\neg A) P(\neg A)}$$
Keterangan:

$P(A|B)$ = Peluang terjadi A jika diketahui B telah terjadi.

$P(B|\neg A)$ = Peluang tidak terjadi A jika diketahui B telah terjadi.

$P(A)$ = Peluang terjadi A

$P(\neg A)$ = Peluang tidak terjadi A


### Characteristics of Naive Bayes

Naive Bayes mengklasifikasi berdasarkan peluang dependen antara prediktor dengan target variabel. Namun, Naive Bayes mengasumsikan tiap prediktor saling independen (tidak berhubungan satu sama lain) dan memiliki bobot yang sama untuk menghasilkan prediksi. Oleh karena itu dinamakan "Naive". Hal ini untuk memudahkan kalkulasi dan mengurangi beban komputasi.

Karakteristik selanjutnya dari Naive Bayes adalah _Skewness Due To Scarcity_. Ketika terdapat suatu prediktor yang frekuensi nilainya 0 untuk salah satu kelas , maka model secara otomatis memprediksi bahwa peluangya adalah 0 untuk kondisi tersebut, tanpa memperdulikan nilai dari prediktor yang lainnya. Solusi alternatif untuk menangani skewness due to data scarcity selain menghilangkan prediktor yang bermasalah tersebut adalah dengan metode _Laplace Smoothing_.

_Laplace Smoothing_ merupakan metode yang menambahkan frekuensi dari setiap prediktor sebanyak angka tertentu (biasanya 1), sehingga tidak ada prediktor yang memiliki nilai 0 dan harus dibuang.

### Study Case : Affiliation Classifier

Sebagai latihan untuk memahami workflow klasifikasi dengan menggunakan metode Naive Bayes, kita akan coba menganalisis data dari United States Congressional Voting tahun 1984. Data berisi informasi tentang hasil voting atau dukungan dari masing-masing anggota kongres dengan affiliasi partai yang berbeda (Republican/Democrat) terhadap berbagai isu atau kebijakan negara.

**Business Question: Lakukan klasifikasi apakah seseorang cenderung berafiliasi dengan partai `Republican` atau `Democrat`.**

### Read Data

Pembacaan data dilakukan, kemudian disimpan dengan variabel `party`

```{r party, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
# chunk untuk menyimpan semua variabel yang digunakan pada party
# baca data
#setwd("D:\LearnR-C2 - Revised")
party <- readRDS("data_input/votes.RDS")

# splitting data
RNGkind(sample.kind = "Rounding")
set.seed(100)
index <- sample(x = nrow(party), size= nrow(party)*0.75)
party_train <- party[index,] # subsetting data berdasarkan index data yang ada di variabel index 
party_test <- party[-index,]

# modeling
model_party <- naiveBayes(party ~ ., data = party_train, laplace = 1)
# prediksi kelas target
party_predClass <- predict(object = model_party, newdata = party_test, type = "class")
# ambil hasil prediksi probability
pred_partyProb <- predict(object = model_party, newdata = party_test, type = "raw")
# membuat data_roc
data_roc <- data.frame(pred_proba = pred_partyProb[, "democrat"],
                       actual = ifelse(party_test$party == "democrat", 1, 0))
# buat objek prediction
roc_pred <- prediction(predictions = data_roc$pred_proba, 
                       labels = data_roc$actual)
```
  
  
```{r}
head(party)
```

Keterangan:

* y = yes (setuju)
* n = no (tidak setuju)
* ? = tidak vote

### Cross-Validation

Lakukan splitting data menjadi data training dan data testing, dengan proporsi data train sebesar 75%. Kemudian simpan data train pada variabel `party_train` dan data test pada variabel `party_test`

```{r splitting, exercise = TRUE, exercise.eval = TRUE}
# index <- sample(x = ..., size= ...)
# party_train <- ...
# party_test <- ...

```

Kemudian lakukan pengecekan pada proporsi kelas target pada data training:

```{r prop, exercise = TRUE, exercise.eval = TRUE}
# Cek proporsi kelas target pada data training

```
<div id="prop-hint">
**Hint:** Gunakan function `prop.table()`
</div>

```{r question-a, echo=FALSE}
question("Berapa persen proporsi kelas target untuk Democrat? (Dib)", type = "single",
correct = "Yap, benar!", incorrect = "Jawaban Anda masih kurang tepat", allow_retry = TRUE,
random_answer_order = FALSE,
answer("40%"),
answer("60%", correct = TRUE),
answer("50%"),
answer("65%"))
```

```{r question-b, echo=FALSE}
question("Dengan toleransi rasio kelas target antara data train dan data test adalah 15%, apakah proporsi untuk masing-masing kelas target sudah seimbang atau tidak?", type = "single",
correct = "Yaps benar!", incorrect = "Jawaban Anda masih kurang tepat", allow_retry = TRUE,
random_answer_order = FALSE,
answer("Tidak seimbang"),
answer("Seimbang", correct = TRUE))
```

### Model Fitting

Lakukan training model menggunakan argumen `naiveBayes()` dengan `party` sebagai target dan variabel lainnya sebagai prediktor. Lalu simpan dengan nama `model_party`. Untuk menangani _data scarcity_, tambahankan parameter `laplace = 1`

```{r train, exercise = TRUE, exercise.eval = TRUE}
# melakukan training model

```
<div id="train-hint">
**Hint:** Struktur _code_ untuk training model: `model_party <- naiveBayes(formula = ... , data = ..., laplace = ...`)
</div>

Lakukan interpretasi masing-masing prediktor dari hasil perhitungan peluang dependennya dengan variabel target. Untuk itu tampilkan `model_party` yang sudah dibuat sebelumnya.
```{r model, exercise = TRUE, exercise.eval = TRUE}

```


```{r question-c, echo=FALSE}
question("Berdasarkan output dari model, manakah pernyataan berikut yang benar? ",
correct = "Yaps benar!", incorrect = "Jawaban Anda masih kurang tepat, cek lagi outputnya!", allow_retry = TRUE,
random_answer_order = FALSE,
answer("Proporsi dari peserta kongres yang setuju terhadap isu crime dan dia mendukung democrat ada sebanyak 0.318 atau 31.8%", correct = TRUE),
answer("Proporsi dari peserta kongres yang tidak setuju terhadap isu dutyfree dan mendukung republican sebanyak 0.843 atau 84%
", correct = TRUE),
answer("Proporsi dari peserta kongres yang tidak memilih terhadap isu immigration dan dia mendukung democrat ada sebanyak 0.25 atau 25%"))
```

### Model Prediction

Lakukan prediksi kelas dari data test dengan function `predict() `, lalu masukan ke dalam variabel `party_predClass`. Berikut keterangan parameter `type` dalam model Naive Bayes:

- `type = "raw"` mengembalikan nilai peluang untuk masing-masing kelas
- `type = "class"` mengembalikan label kelasnya (_default threshold_ 0.5)

```{r pred, exercise = TRUE, exercise.eval = TRUE}
# prediksi kelas target

```

<div id="pred-hint">
**Hint:** Struktur _code_ untuk prediksi kelas: `party_predClass <- predict(object = ..., newdata = ..., type = "...")`
</div>

### Model Evaluation

Lakukan evaluasi model dengan menampilkan confusion matrix.

```{r eval_model, exercise = TRUE, exercise.eval = TRUE}
# evaluasi model dengan Confusion Matrix

```

```{r question-d, echo=FALSE}
question("Dikarenakan data yang digunakan dianggap seimbang (balance) dan setiap kelas dianggap penting, maka metrics manakah yang diunggulkan dalam evaluasi model? ", type = "single",
correct = "Yaps benar!", incorrect = "Cek lagi outputnya!", allow_retry = TRUE,
random_answer_order = FALSE,
answer("Pos Pred Value/Precision"),
answer("Specificity"),
answer("Sensitivity"),
answer("Accuracy", correct = TRUE))
```

```{r question-e, echo=FALSE}
question("Berapakah nilai akurasi yang diperoleh dari model? ",
correct = "Yaps benar!", incorrect = "Cek lagi outputnya!", allow_retry = TRUE,
random_answer_order = FALSE,
answer("87%", correct = TRUE),
answer("80%"),
answer("72%"),
answer("92%")
)
```

Berdasarkan metrics akurasi, model dengan Naive Bayes yang diperoleh dapat dikatakan sudah cukup baik dalam melakukan klasifikasi dan prediksi pada data. Namun catatan penting yang perlu diketahui, ketika data yang kita miliki imbalance dan kita ingin melihat seberapa baik model dalam membedakan kedua kelas (kelas positif & kelas negatif) dengan baik, maka dibutuhkan metrics lain yaitu ROC (Receiver-Operating Curve) dan AUC (Area Under Curve).

### Receiver-Operating Curve (ROC)

ROC adalah kurva yang menghubungkan antara _True Positive Rate_ dengan _False Positive Rate_. Model yang baik idealnya memiliki _True Positive Rate_ yang tinggi dan _False Positive Rate_ yang rendah.

Mari kita buat kurva ROC dari model `model_party`. Untuk itu, langkah pertama adalah melakukan prediksi kembali terhadap data test, namun kali ini kita mengambil nilai peluang untuk masing-masing kelas. Simpan hasil prediksi probabilitas dengan nama `pred_partyProb`

```{r pred_target, exercise = TRUE, exercise.eval = TRUE}
# prediksi probabilitas

```

Untuk mempermudah, kita siapkan data frame untuk ROC dengan asumsi kelas positifnya adalah "democrat".

```{r}
data_roc <- data.frame(pred_proba = pred_partyProb[, "democrat"],
                       actual = ifelse(party_test$party == "democrat", 1, 0))
head(data_roc)
```

Selanjutnya buat kurva ROC dengan menyiapkan objek `prediction()`:

```{r roc, exercise = TRUE, exercise.eval = TRUE}
# buat objek prediction
# roc_pred <- prediction(predictions = ..., labels = ...)

# buat plot dari objek prediction
# plot(performance(prediction.obj = ..., measure = "tpr", x.measure = "fpr"))
```

<div id="roc-hint">
**Hint:** Berikut keterangan untuk parameter pada function `prediction()`:

- predictions → nilai dari prediksi probabilitas (`pred_proba`) pada `data_roc`
- labels → nilai `actual` dari `data_roc`
</div>

Berikut output yang diharapkan:

```{r echo=FALSE, message=FALSE}
# buat objek prediction
roc_pred <- prediction(predictions = data_roc$pred_proba, 
                       labels = data_roc$actual)

# buat plot dari objek prediction
plot(performance(prediction.obj = roc_pred, measure = "tpr", x.measure = "fpr"))
```

### Area Under ROC Curve (AUC)

AUC menunjukkan luas area di bawah kurva ROC. Semakin nilai AUC mendekati 1, maka semakin bagus performa modelnya. Gunakan function `performance()` untuk mendapatkan nilai AUC.

```{r auc, exercise = TRUE, exercise.eval = TRUE}
# auc_value <- performance(prediction.obj = ..., measure = ...)
# auc_value@y.values 

```

```{r question-f, echo=FALSE}
question("Berdasarkan output yang dihasilkan, manakah pernyataan berikut yang benar?",
correct = "Yaps benar!", incorrect = "Jawaban Anda masih kurang tepat, cek lagi outputnya!", allow_retry = TRUE,
random_answer_order = FALSE,
answer("Nilai AUC yang dihasilkan sebesar 0.969, artinya model mampu mengklasifikasikan kelas positif dan kelas negatif dengan baik.", correct = TRUE),
answer("Nilai AUC yang dihasilkan sebesar 0.969, artinya model tidak mampu mengklasifikasikan kelas positif dan kelas negatif dengan baik."),
answer("Nilai AUC yang dihasilkan sebesar 0.969, artinya model hanya baik memprediksi salah satu kelas saja."))
```


## Bab 2 : Text Mining

Text Mining adalah salah satu metode analisis data untuk mendapatkan informasi dan pola-pola yang berguna dari sekumpulan dokumen. Maka sumber data yang digunakan pada text mining adalah kumpulan teks yang memiliki format yang tidak terstruktur. Salah satu algoritma yang sering digunakan untuk kasus klasifikasi dari data teks adalah Naive Bayes. Hal ini dikarenakan waktu komputasi cukup cepat untuk prediktor kata yang banyak. 

Secara umum, workflow pada text mining adalah:

1. Read Data
2. Data Wrangling
3. Exploratory Data Analysis
4. Data Pre-processing:
   a. Mengubah teks menjadi corpus
   b. _Corpus cleansing_
   c. Mengubah corpus menjadi Document-Term Matrix
5. Cross-Validation
6. Further Data Pre-processing:
   a. Feature Selection dengan `findFreqTerms()`
   b. Bernoulli Converter
7. Pembuatan Model
8. Prediksi Data Test
9. Model Evaluation

### Study Case: Spam Classifier

Sebagai latihan untuk memahami workflow klasifikasi pada data teks menggunakan metode Naive Bayes, kita akan menganalisis data sms yang telah memiliki label spam atau ham.

**Business Question:** Berdasarkan kata-kata pada SMS, kita ingin melakukan klasifikasi apakah suatu SMS termasuk spam atau bukan (ham). Kelas positif atau kelas yang ingin difokuskan pada _case_ ini adalah `spam`

### Read Data

Pembacaan data dilakukan, kemudian disimpan dengan variabel `sms_raw`

```{r sms, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
# chunk untuk menyimpan semua variabel yang digunakan pada sms_raw
# baca data
# setwd("D:/ALGORITMA/DST/DSS Project #2/LearnR-C2")

sms <- readRDS("data_input/sms.RDS")
sms_corpus_clean <- readRDS("rds-files/sms_corpus_clean.RDS")

# ubah format menjadi corpus
sms_corpus <- VCorpus(VectorSource(sms$text))

# ubah menjadi Document Term Matrix
sms_dtm <- DocumentTermMatrix(sms_corpus_clean)

```


```{r sms-2, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
# read doc term matrix
# setwd("D:/ALGORITMA/DST/DSS Project #2/LearnR-C2")
sms <- readRDS("data_input/sms.RDS")

sms_dtm <- readRDS("rds-files/sms_dtm.RDS")

# melakukan splitting berdasarkan sms_dtm
RNGkind(sample.kind = "Rounding")
set.seed(100)

intrain <- sample(nrow(sms_dtm), nrow(sms_dtm)*0.75)
# train-test splitting
sms_train <- sms_dtm[intrain,]
sms_test <- sms_dtm[-intrain,]

# ambil label target untuk data train
label_train <- sms[intrain, "label"]
# ambil label target untuk data test
label_test <- sms[-intrain, "label"]

# mengambil kata yang sering muncul
sms_freq <- findFreqTerms(sms_train, lowfreq = 20)
# subsetting sms_train terhadap kata `sms_freq` 
sms_train <- sms_train[, sms_freq]

# function bernoulli
bernoulli_conv <- function(x){
  # parameter ifelse: kondisi, TRUE, FALSE
  x <- as.factor(ifelse(x > 0, 1, 0)) 
  return(x)
}

# bernoulli converter
sms_train_bn <- apply(X = sms_train, MARGIN = 2, FUN = bernoulli_conv)
sms_test_bn <- apply(X = sms_test, MARGIN = 2, FUN = bernoulli_conv)

# melakukan training model
model_spam <- naiveBayes(x = sms_train_bn, # variabel prediktor
                         y = label_train, # variabel target
                         laplace = 1)
```


```{r sms-3, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
# read required files

# setwd("D:/ALGORITMA/DST/DSS Project #2/LearnR-C2")
sms <- readRDS("data_input/sms.RDS")

model_spam <- readRDS("rds-files/model_spam.RDS")
sms_test_bn <- readRDS("rds-files/sms_test_bn.RDS")
label_test <- readRDS("rds-files/label_test.RDS")

# melakukan prediksi pada data test
sms_predClass <- predict(object= model_spam, newdata = sms_test_bn, type = "class") 
head(sms_predClass) 

# evaluasi model dengan Confusion Matrix
confusionMatrix(as.factor(sms_predClass), reference = label_test, positive = "spam")

# prediksi probabilitas
sms_pred_prob <- predict(object = model_spam, newdata = sms_test_bn, type = "raw")

# simpan ke bentuk data frame
data_sms_roc <- data.frame(pred_prob_sms = sms_pred_prob[, "spam"],
                           actual = label_test)

# hasil object `prediction()`
sms_roc <- prediction(predictions = data_sms_roc$pred_prob_sms, labels = data_sms_roc$actual)

# menghitung nilai AUC
sms_value <- performance(prediction.obj = sms_roc, measure = "auc")
```

```{r}
head(sms)
```

Deskripsi data :

 - `label`: status SMS (spam/ham)
 - `text`: teks SMS 

### Exploratory Data Analysis (EDA)

Silahkan ambil 5 sampel teks yang termasuk spam menggunakan function `filter`. Kemudian amati kata-kata apa saja yang dapat menjadi indikator (prediktor) bahwa suatu text adalah spam?

```{r eda, exercise = TRUE, exercise.eval = TRUE}
# tampilkan 5 sampel teks yang termasuk spam

```

```{r question-g, echo=FALSE}
question("Berdasarkan output yang dihasilkan, manakah dari kata-kata berikut yang berpotensial mengindikasi bahwa suatu teks adalah spam",
correct = "Yaps benar!", incorrect = "Jawaban Anda masih kurang tepat. Jawaban bisa lebih dari satu!", allow_retry = TRUE,
random_answer_order = FALSE,
answer("FREE", correct = TRUE),
answer("PRIZE", correct = TRUE),
answer("AVALAIBLE"))
```

### Data Preprocessing

Tahap selanjutnya adalah data preprocessing, yang merupakan salah satu tahapan persiapan dan pembersihan data agar bisa digunakan untuk pengolahan selanjutnya..

#### Text to Corpus

Sebelum pembersihan data lebih lanjut, teks perlu diubah menjadi format corpus. Corpus adalah kumpulan dari dokumen. Pada kasus ini, satu dokumen ekuivalen dengan satu observasi SMS. 

Ubahlah teks menjadi corpus dengan menggunakan function `VCorpus()`, lalu simpan pada variabel `sms_corpus` 


```{r corpus, exercise = TRUE, exercise.eval = TRUE}
# ubah format menjadi corpus

```

#### Text Cleansing

Lakukan pembersihan data menggunakan _function_ `tm_map` berdasarakan langkah-langkah berikut. Lalu simpan hasil _text cleaning_ dengan nama `sms_corpus_clean`

- Mengubah semua huruf kapital menjadi huruf kecil agar menyamakan format pada teks.
- Menghapus angka dikarenakan pada umumnya angka tidak mengandung arti yang signifikan
- Menghilangkan kata-kata umum yang kurang bermakna yang biasanya muncul dalam jumlah besar (stopwords)
- Menghilangkan tanda baca (_punctuation_). Tanda baca yang dihilangkan: ! ' # S % & ' ( ) * + , - . / : ; < = > ? @ [ / ] ^ _ { | } ~
- Menghapus kata-kata imbuhan yang kurang bermakna atau pemotongan kata menjadi kata dasarnya dengan _function_ . Misalnya _'walking'_, _'walked'_, _'walks'_ menjadi _'walk'_. Proses ini dilakukan untuk menyeragamkan setiap kata menjadi bentuk baku agar prediktor tidak berulang.
- Menghapus spasi berlebih (_white space_). Proses ini penting dilakukan karena pada tahap selanjutnya yaitu _tokenizing_ dan pembuatan document-term-matrix akan mengambil kata perkata dengan separator spasi "_"

```{r convert, eval=F}
# case-folding: mengubah semua text menjadi lowercase
sms_corpus_lower <- tm_map(sms_corpus, content_transformer(tolower))

# remove numbers: menghapus angka
sms_corpus_numb <- tm_map(sms_corpus_lower, removeNumbers)

# remove stopwords: menghapus kata umum yang kurang bermakna
sms_corpus_stop <- tm_map(sms_corpus_numb, removeWords, stopwords("english"))
  
# remove punctuation: menghapus tanda baca
sms_corpus_punc <- tm_map(sms_corpus_stop, removePunctuation)

# stemming: mengembalikan kata dasar
sms_corpus_stem <- tm_map(sms_corpus_punc, stemDocument)

# remove white space: menghapus spasi berlebih
sms_corpus_clean <- tm_map(sms_corpus_stem, stripWhitespace)
  
```

Selanjutnya kita coba cek content ke-9 sebelum cleaning

```{r check}
sms_corpus[[9]]$content
```

Kemudian inilah hasil dari cleaning content ke-9

```{r check2}
sms_corpus_clean[[9]]$content
```


### Document-Term Matrix (DTM)

Sampai di tahap ini, data kita masih berupa text. Maka untuk keperluan modeling pada klasifikasi, kita perlu melakukan transformasi data text menjadi Document-Term Matrix (DTM) melalui proses tokenization. Tokenization adalah proses memecah satu kalimat menjadi beberapa term (bisa berupa 1 kata, pasangan kata, dll). Dalam DTM, 1 kata akan menjadi 1 prediktor dengan nilai berupa frekuensi kemunculan kata tersebut dalam sebuah dokumen.

Ubahlah text menjadi Document-Term Matrix dan simpan pada variabel `sms_dtm`. Kemudian lakukan inspeksi pada variabel tersebut dengan function `inspect()`

```{r dtm, exercise = TRUE, exercise.eval = TRUE}
# ubah menjadi Document Term Matrix
sms_dtm <- 

inspect(sms_dtm)
```


```{r question-h, echo=FALSE}
question("Berdasarkan hasil inspeksi dari hasil konversi ke Document-Term Matrix, berapakah kata unik yang muncul di seluruh SMS?", type = "single",
correct = "Yaps benar!", incorrect = "Jawaban Anda masih kurang tepat. Perhatikan output kembali!", allow_retry = TRUE,
random_answer_order = FALSE,
answer("5572"),
answer("6474", correct = TRUE),
answer("42354"),
answer("36030774"))
```


```{r question-i, echo=FALSE}
question("Berdasarkan hasil inspeksi dari hasil konversi ke Document-Term Matrix, berapakah nilai 0 yang muncul pada matrix di seluruh SMS?", type = "single",
correct = "Yaps benar!", incorrect = "Jawaban Anda masih kurang tepat. Perhatikan output kembali!", allow_retry = TRUE,
random_answer_order = FALSE,
answer("5572"),
answer("6474"),
answer("42354"),
answer("36030774", correct = TRUE))
```

### Cross-Validation

Langkah selanjutnya adalah splitting data menjadi `sms_train` dan `sms_test` dengan dengan proporsi data train sebesar 75%. 

```{r cv, exercise = TRUE, exercise.eval = TRUE}
# melakukan splitting data train dan data test
intrain <- 
sms_train <- 
sms_test <- 

# cek dimensi sms train dan sms test
dim(sms_train)
dim(sms_test)
```

Kemudian siapkan juga label untuk variabel target dari masing-masing data train dan data test. Simpan dengan nama variabel `label_train` dan `label_test`.

```{r label, exercise = TRUE, exercise.eval = TRUE}
# ambil label target untuk data train 

# ambil label target untuk data test

```

### Further Data Preprocessing

#### Remove Infrequent Words

Langkah selanjutnya adalah menghapus kata yang jarang muncul. Tahap ini dilakukan untuk mengurangi _noise_ dan menyeleksi _features_ / prediktor berdasarkan kata-kata yang sering muncul saja. 

Gunakan function `findFreqTerms()` untuk mengambil kata yang sering muncul pada `sms_train` minimal sebanyak 20 kali. Lalu simpan dengan nama variabel `sms_freq`. Kemudian lakukan subsetting `sms_train` hanya untuk kata-kata yang muncul di `sms_train`

```{r freq, exercise = TRUE, exercise.eval = TRUE}
## mengambil kata yang sering muncul
# sms_freq <- 

## subsetting sms_train terhadap kata `sms_freq` 
# sms_train <- 

## inspeksi   
# inspect(sms_train)
```


#### Bernoulli Converter

Nilai pada matrix `sms_train` masih berupa frekuensi. Untuk perhitungan peluang, frekuensi akan diubah menjadi hanya kondisi muncul (1) atau tidak (0). Salah satu caranya dengan menggunakan **Bernoulli Converter**.

- Jika frekuensi >= 1, maka bernilai 1 (muncul)
- Jika frekuensi == 0, maka bernilai 0 (tidak muncul)

Untuk itu, selanjutnya sudah dibuat sebuah fungsi dengan nama `bernoulli_conv`

```{r}
bernoulli_conv <- function(x){
  # parameter ifelse: kondisi, TRUE, FALSE
  x <- as.factor(ifelse(x > 0, 1, 0)) 
  return(x)
}

```

Selanjutnya, terapkan `bernoulli_conv` ke `sms_train` dan `sms_test`. Simpan dengan nama `sms_train_bn`. Kemudian lakukan subsetting untuk mengecek hasil aplikasi bernoulli converter pada sms_train_bn

```{r bernoull, exercise = TRUE, exercise.eval = TRUE}

# aplikasi bernoulli_conv pada sms_train
# sms_train_bn <- apply(X = ..., MARGIN = ..., FUN = ...)

# aplikasi bernoulli_conv pada sms_test
# sms_test_bn <- apply(X = ..., MARGIN = ..., FUN = ...)

# subset baris dal kolom
sms_train_bn[6:10, 6:10]
```

Output yang diharapkan ketika melakukan subset baris = 6-10 dan kolom = 6 - 10 adalah:  
```{r}
sms_train_bn[6:10, 6:10]
```

Nilai matrix yang dihasilkan sudah berupa `binary` yaitu 0 (tidak muncul) dan 1 (muncul).

### Model Fitting

Persiapan data sudah selesai, selanjutnya  buatlah model Naive Bayes dengan `label_train` sebagai target dan variabel `sms_train_bn` sebagai prediktor. Lalu simpan dengan nama `model_spam`. Untuk menangani _data scarcity_, tambahankan parameter `laplace = 1`

```{r train-sms, exercise = TRUE, exercise.eval = TRUE}
# melakukan training model

```

### Model Prediction

Lakukan prediksi kelas target pada `sms_test_bn` berdasarkan model yang sudah dibangun. Simpan ke objek `sms_pred_class`.

```{r test-sms, exercise = TRUE, exercise.eval = TRUE}
# melakukan prediksi pada data test

```

### Model Evaluation

Langkah selanjutnya adalah evaluasi model, kali ini kita akan mencoba menggunakan Confusion Matrix dan ROC/AUC.

#### Confusion Matrix

Lakukan evaluasi `model_spam` terhadap hasil prediksi data test menggunakan confusion matrix. Ingat bahwa target yang menjadi kelas positif adalah `spam`

```{r eval-sms, exercise = TRUE, exercise.eval = TRUE}
# evaluasi model dengan Confusion Matrix

```

```{r question-j, echo=FALSE}
question("Apabila kita tidak ingin sms yang penting (ham) masuk ke dalam spam, maka metrics mana yang kita perhatikan?", type = "single",
correct = "Yaps benar!", incorrect = "Jawaban Anda masih kurang tepat.", allow_retry = TRUE,
random_answer_order = FALSE,
answer("Precision/Pos Pred Value karena kita ingin meminimalisir False Positive", correct = TRUE),
answer("Precision/Pos Pred Value karena kita ingin meminimalisir False Negative"),
answer("Recall/Sensitivity karena kita ingin meminimalisir False Positive"),
answer("Recall/Sensitivity karena kita ingin meminimalisir False Negative"))
```

#### ROC and AUC

Untuk meninjau ROC dan AUC, kita perlu mempersiapkan hasil prediksi berupa probability dari `sms_test_bn`, simpan ke objek dengan nama `sms_pred_prob`:

```{r prob-sms, exercise = TRUE, exercise.eval = TRUE}
# prediksi probabilitas

```

Untuk mempermudah, kita siapkan data frame untuk ROC yang disimpan ke objek dengan nama `data_sms_roc`:

```{r}
data_sms_roc <- data.frame(pred_prob_sms = sms_pred_prob[, "spam"],
                           actual = label_test)
```

Selanjutnya buatlah kurva ROC. Simpan hasil object `prediction()` dengan nama `sms_roc`:

```{r roc_sms, exercise = TRUE, exercise.eval = TRUE}
# buat objek prediction

# buat plot dari objek prediction

```

Berikut output yang diharapkan:
```{r echo=FALSE, message=FALSE}
# buat objek prediction
sms_roc <- prediction(predictions = data_sms_roc$pred_prob_sms, labels = data_sms_roc$actual) 

# buat plot dari objek prediction
plot(performance(prediction.obj = sms_roc, measure = "tpr", x.measure = "fpr"))
```

Hitung nilai AUC dengan menggunakan function `performance()`

```{r auc_sms, exercise = TRUE, exercise.eval = TRUE}
# menghitung nilai AUC

```

```{r question-k, echo=FALSE}
question("Berdasarkan output yang dihasilkan, manakah pernyataan berikut yang benar?",
correct = "Yaps benar!", incorrect = "Jawaban Anda masih kurang tepat, cek lagi outputnya!", allow_retry = TRUE,
random_answer_order = FALSE,
answer("Nilai AUC yang dihasilkan sebesar 0.97, artinya model mampu mengklasifikasikan kelas positif dan kelas negatif dengan baik.", correct = TRUE),
answer("Nilai AUC yang dihasilkan sebesar 0.97, artinya model tidak mampu mengklasifikasikan kelas positif dan kelas negatif dengan baik."),
answer("Nilai AUC yang dihasilkan sebesar 0.97, artinya model hanya baik memprediksi salah satu kelas saja."))
```

## Bab 3 : Decision Tree

Decision Tree merupakan _tree-based model_ yang cukup sederhana dengan performa yang _robust_ dan _powerful_ untuk melakukan prediksi. Metode ini menghasilkan visualisasi berupa pohon keputusan yang dapat diinterpretasi dengan mudah. Karakteristik lainnya pada Decision Tree adalah antar variabel prediktornya diasumsikan saling dependent. Sehingga algoritma ini dapat mampu mengatasi _multicollinearity_ dan _outlier_. Kemudian Desicion Tree mampu melakukan prediksi baik dengan prediktor numerik maupun kategorik.

Berikut komponen dalam Desicion Tree:

- **Root Node**: Percabangan pertama dalam menentukan nilai target, biasa disebut sebagai predictor utama.
- **Interior Node**: Percabangan selanjutnya yang menggunakan predictor lain apabila root node tidak cukup dalam menentukan target.
- **Terminal/Leaf Node**: Keputusan akhir berupa nilai target yang diprediksi.

Dalam memilih predictor pada setiap percabangannya, Decision Tree akan memilih predictor yang sebisa mungkin meng-homogen-kan target variable pada leaf node nya. Tingkat kehomogenan ini dapat dikuantifikasi menggunakan **Entropy** dan **Information Gain**.

### Entropy and Information Gain

Entropy adalah ukuran ketidakteraturan (measure of disorder) dari sebuah kelompok data. Nilai entropy berkisar antara 0 sampai 1. Entropy bernilai 1 artinya tidak ada kelas yang dominan (proporsi seimbang, 50:50), sedangkan entropy bernilai 0, artinyasalah satu kelas sangat dominan (proporsi 100:0).

Kelompok data yang diharapkan setelah dilakukan percabangan adalah kelompok yang memiliki entropy rendah. Kemudian untuk predictor yang dipilih adalah predictor yang menghasilkan penurunan entropy paling besar, karena berarti membuat data setelah pemisahan semakin homogen. Perubahan entropy inilah yang disebut Information Gain.

### Study Case: Heart Disease

**Business Question:** Sebagai seorang konsultan kesehatan di sebuah rumah sakit, kita diminta untuk membuat _rules_ dari hasil tes diagnosis dan riwayat kesehatan jantung 303 pasien. Dalam kasus ini, kita akan mengaplikasikan Decision Tree untuk melakukan klasifikasi pasien yang terkena serangan jantung dan tida. Decision Tree juga merupakan metode yang tepat agar rules dapat disajikan dalam bentuk visualisasi dan mudah diinterpretasi. 


### Read Data

Pembacaan data dilakukan, kemudian disimpan dengan variabel `heart`

```{r data_heart, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
# chunk untuk menyimpan semua variabel yang digunakan pada party
# baca data
# setwd("D:/ALGORITMA/DST/DSS Project #2/LearnR-C2")
heart<-readRDS("data_input/heart.RDS")

# splitting train dan test
set.seed(250)
intrain <- sample(nrow(heart),nrow(heart)*0.8)
heart_train <- heart[intrain, ]
heart_test <- heart[-intrain, ]

# upsampling
set.seed(250)
heart_train_up <- upSample(x = heart_train[, -14],
                              y = heart_train$target,
                              yname = "target")

# membuat model tree
heart_tree <- ctree(target~., heart_train_up)

# prediksi data train
heart_pred_train <- predict(heart_tree, heart_train)

# prediksi data test
heart_pred_test <- predict(heart_tree, heart_test)

# parameter tunning
#heart_model_new <- ctree(form= target~., data = heart_train_up, 
#                        control = ctree_control(mincriterion = 0.7,
#                                                minsplit = 40,
#                                                minbucket = 20))

# read model
heart_model_new <- readRDS("rds-files/heart_model_new2.RDS")

# prediksi data train dengan heart_model_new
pred_train_new <- predict(heart_model_new, heart_train)

# prediksi data test dengan heart_model_new
pred_test_new <- predict(heart_model_new, heart_test)

# read model
heart_forest <- readRDS("rds-files/heart_forest.RDS")

# prediksi data train
heart_pred_forest_train <- predict(object = heart_forest, newdata = heart_train)

# prediksi data test
heart_pred_forest_test <- predict(object = heart_forest, newdata = heart_test)
```

 
```{r}
head(heart)
```

Deskripsi data:

- `age` : Usia pasien (tahun)
- `sex`	Jenis kelamin pasien (Male=laki-laki; Female=perempuan)
- `cp` : Jenis nyeri dada (0=typical angina; 1=atypical angina; 2=non-anginal pain; 3=asymptomatic)
- `trestbps` : Tekanan darah (dalam mm Hg))
- `chol` :	Kolesterol serum (dalam mg/dl)
- `fbs` : Gula darah ketika puasa >120mg/dl (True=benar; False=salah)
- `restecg` :	Hasil resting elektrokardiografi (0=normal; 1=ST-T abnormal; 2=hipertrofi ventrikel kiri)
- `thalach` :	Detak jantung maksimum
- `exang`	: Olahraga untuk induksi angina (Yes=ya; No=tidak)
- `oldpeak` :	Depresi ST yang diakibatkan oleh latihan relative terhadap saat istirahat
- `slope` :	Perubahan kemampuan bicara (1=naik; 2=netral; 3=menurun)
- `ca` :	Pembuluh darah (0=normal; 1=arteri coroner; 2=aneurisma; 3=arteri perifer)
- `thal`:	Thalassemia (1=cacat tetap; 2=normal; 3=cacat sementara)
- `target` :	Penyakit jantung (Health=tidak terkena serangan jantung; Not Health=terkena serangan jantung)


### Cross-Validation

Dikarenakan tipe data sudah sesuai, tidak ada missing value, dan data sudah dianggap bersih, maka langkah selanjutnya adalah melakukan split data `heart` menjadi `heart_train` dan `heart_test` dengan proporsi 80:20.

```{r split_heart, exercise = TRUE, exercise.eval = TRUE}
## melakukan splitting data train dan data test
set.seed(250)
# intrain <- 
# heart_train <- 
# heart_test <- 

# cek proporsi heart_train dan heart_test
prop.table(table(heart_train$target))

# cek proporsi heart_train dan heart_test
prop.table(table(heart_test$target))
```

Setelah melakukan splitting, maka seharusnya proporsi kelas di data training adalah sebagai berikut:

```{r}
prop.table(table(heart_train$target))
```

Sedangkan proporsi kelas di data test adalah sebagai berikut:

```{r}
prop.table(table(heart_test$target))
```

Berdasarkan output yang dihasilkan, proporsi `heart_train` dan `heart_test` sebenarnya masih bisa dianggap balance. Namun kita bisa coba membuatnya lebih balance lagi sehingga proporsinya 50:50. Teknik yang bisa digunakan adalah:

- **Upsample** : menambahkan observasi minoritas hingga seimbang dengan mayoritas, dengan menduplikat data dari observasi minoritas. 
- **Downsample** : mengurangi observasi mayoritas hingga seimbang dengan yang minoritas.  

Pada kasus ini karena kita tidak ingin kehilangan data, maka lakukanlah upsampling dengan menggunakan fungsi dari _library_ `caret` yaitu _function_ `upSample()`. Simpan hasil penyeimbangan kelas target pada variabel `heart_train_up`

```{r up_heart, exercise = TRUE, exercise.eval = TRUE}
# heart_train_up <- upSample(x = ..., y = ..., yname = ...) 


# cek proporsi data train
prop.table(table(heart_train_up$target))
```

<div id="up_heart-hint">
**Hint:** Berikut keterangan untuk parameter pada function `upSample()`:
- x → mengambil variabel prediktor pada `heart_train` 
- y → mengambil variabel target pada `heart_train`
- y_name → nama kolom variabel target 
</div>

### Model Fitting

Lakukan training model pada data `heart_train_up` dengan Decision Tree menggunakan argumen `ctree()`. Gunakan kolom `target` sebagai variabel target dan kolom lainnya sebagai prediktor. Lalu simpan dengan nama `heart_tree`. 

Kemudian tampilkan stuktur tree dengan memanggil model nya 
```{r train_heart, exercise = TRUE, exercise.eval = TRUE}
# melakukan training model
# heart_tree <- 

# print struktur pohon
plot(heart_tree, type = "simple")
```

Berikut output yang diharapkan: 


```{r echo=FALSE, message=FALSE}
plot(heart_tree, type = "simple")
```

```{r question-l, echo=FALSE}
question("Berdasarkan struktur tree dari model, ketika ada seorang pasien dengan thalassemia normal (thal = 2), kondisi pembuluh darah arteri coroner (ca = 1), dan mengidap nyeri dada asymptomatic (cp = 3), maka pada kelas mana model akan mengklasifikasikan pasien tersebut?", type = "single",
correct = "Yaps benar!", incorrect = "Jawaban Anda masih kurang tepat. Perhatikan output kembali!", allow_retry = TRUE,
random_answer_order = FALSE,
answer("Not Health", correct = TRUE),
answer("Health"))
```

```{r question-m, echo=FALSE}
question("Berdasarkan struktur tree, berapakah persentase kesalahan prediksi yang dihasilkan model dalam mengklasifikasikan pasien dengan dengan thalassemia cacat sementara (thal = 3), mengidap nyeri dada non-anginal pain (cp =2), dan mengalami perubahan kemampuan bicara yang menaik (slope = 1)?", type = "single",
correct = "Yaps benar!", incorrect = "Jawaban Anda masih kurang tepat. Perhatikan output kembali!", allow_retry = TRUE,
random_answer_order = FALSE,
answer("9,1%"),
answer("18.2%", correct = TRUE),
answer("25,0%"), 
answer("15.4%"))
```


### Model Prediction

Lakukan prediksi kelas dari data test dengan function `predict()`, lalu masukan ke dalam variabel `heart_pred_test`. 

```{r pred_heart, exercise = TRUE, exercise.eval = TRUE}
##prediksi kelas di data test
# heart_pred_test <- 

```

### Model Evaluation

Berdasarkan hasil prediksi di data test, lakukan evaluasi model `heart_tree` menggunakan confusion matrix. Inisiaasi kelas positif pada kasus ini adalah `Not Health`

```{r confusion_heart, exercise = TRUE, exercise.eval = TRUE}
# evaluasi model terhadap data test dengan Confusion Matrix

```

```{r question-n, echo=FALSE}
question("Apabila kita tidak ingin pasien yang terkena serangan jantung (Not Health) namun diklasifikasikan kepada kelas yang tidak terkena serangan jantung (Health), maka nilai apa yang ingin kita kurangi atau minimalisir? Dimana kelas positif pada kasus ini adalah 'Not Health'", type = "single",
correct = "Yaps benar!", incorrect = "Jawaban Anda masih kurang tepat.", allow_retry = TRUE,
random_answer_order = FALSE,
answer("False Positif"),
answer("False Negatif", correct = TRUE))
```

```{r question-o, echo=FALSE}
question("Kemudian metric apakah yang kita perhatikan?", type = "single",
correct = "Yaps benar!", incorrect = "Jawaban Anda masih kurang tepat.", allow_retry = TRUE,
random_answer_order = FALSE,
answer("Accuracy"),
answer("Sensitivity/Recall", correct = TRUE),
answer("Specificity"),
answer("Pos Pred Value/Precision"))
```

Untuk mengetahui kondisi fitting dari suatu model, lakukan juga prediksi pada data train, lalu simpan dengan nama `heart_pred_train`. Kemudian  cek _performance model_ terhadap prediksi data train

```{r pred_train_heart, exercise = TRUE, exercise.eval = TRUE}
## prediksi kelas di data train
# heart_pred_train <- 
```

```{r eval_train_heart, exercise = TRUE, exercise.eval = TRUE}
# confusion matrix data train

```

Maka diperoleh nilai evaluasi dari model:

- Sensitivity/Recall di data train: 89%%
- Sensitivity/Recall di data test: 72%

Ketika dibandingkan, performa model `heart_tree` cenderung lebih baik pada data train dibandingkan data test. Model ini dikatakan sebagai model yang _overfitting_. Karena performa model belum cukup baik, perlu dilakukan _model tuning_.

### Bias-Variance Tradeoff

Dalam pembuatan model, model berusaha mempelajari pola yang terdapat dalam data sehingga dihasilkan suatu aturan yang dapat memprediksi kelas/nilai target dengan tepat. Untuk masing-masing model machine learning, terdapat karakteristik yang disebut _bias_ dan _variance_.

- _bias_: perbedaan antara hasil prediksi dengan nilai aktual
- _variance_: variasi hasil prediksi yang mungkin muncul pada titik data tertentu

_Bias-Variance Tradeoff_ menyatakan bahwa semakin sederhana suatu model, maka akan semakin tinggi bias dan semakin rendah variancenya; begitupun sebaliknya.

Terdapat 3 kondisi dari model machine learning berdasarkan kemampuanya melakukan prediksi:

* Underfitting: keadaan model yang memiliki bias tinggi dan variance rendah sehingga hasil prediksinya tidak terlalu tepat
* Overfitting: keadaan model yang memiliki variance tinggi dan bias rendah sehingga prediksi di data trainnya amat tepat, namun performanya buruk dalam memprediksi data test 
* Just Right: kondisi model yang memiliki bias dan variance yang saling berimbang (kondisi yang diharapkan). Salah satu tujuan dari model tuning adalah mendapatkan bias-variance trade-off yang optimal.

### Pruning and Tree-size

Kekurangan dari Decision Tree adalah kecenderungannya untuk overfitting. Hal ini terjadi karena Decision tree mampu membagi-bagi data hingga amat detail. Hal ini membuat Decision Tree justru menghafal pola di data train, dan membuat aturan yang terlalu kompleks, bukan mempelajari pola tersebut. Alhasil model menjadi kurang general untuk diaplikasikan ke data yang bukan data train, sehingga cenderung _overfitting_. 

Untuk mengatasinya, Decision Tree perlu tahu kapan ia berhenti membuat cabang sehingga pohon yang dihasilkan tidak terlalu kompleks. Pemotongan/pencegahan cabang pohon itu dinamakan _Pruning_, dimana kita mencegah Decision Tree untuk membuat cabang berdasarkan kriteria tertentu. 

Pruning terbagi menjadi 2 cara:

- Pre-Pruning: memasang parameter sebelum model dihasilkan terlebih dahulu . Metode ini kurang disarankan karena kita belum memiliki informasi tentang parameter apa yang sebaiknya kita atur.

- Post-Pruning: Pruning setelah kita mendapatkan model yang lengkap atau kompleks, lalu menentukan seberapa jauh kita akan memangkas cabang pada Decision Tree.

Parameter pruning:

- mincriterion: Nilai 1-$\alpha$. Saat mincriterion 0.95, P-value harus < 0.05 untuk suatu node dapat membuat cabang. (default: 0.95)
- minsplit: Jumlah minimal observasi di tiap cabang setelah pemisahan. Bila tidak terpenuhi, tidak dilakukan percabangan. (default: 20)
- minbucket: Jumlah minimal observasi di terminal node. Bila tidak terpenuhi, tidak dilakukan percabangan. (default: 7)

Dikarenakan model `heart_tree` mengalami overfitting atau pohon yang terlalu kompleks dengan parameter default, maka yang dapat dilakukan adalah meninggikan nilai untuk parameter mincriterion, minsplit dan minbucket.

Buatlah tuning model `heart_tree` dengan mengatur parameter _pruning_ dengan nilai mincriterion = 0.7, minsplit = 40, dan minbucket = 20. Lalu simpan pada variabel `heart_model_new`. 

```{r tuning, exercise = TRUE, exercise.eval = TRUE}
# heart_model_new <- ctree(formula = ..., data = ..., control = ctree_control())
```

<div id="tuning-hint">
**Hint:** Atur nilai mincriterion, minsplit, dan minbucket pada argumen `ctree_control()`
</div>

Lakukan prediksi kelas dengan model tuning pada data `heart_train` dan simpan dengan nama `heart_train_new`

```{r pred_train_tuning, exercise = TRUE, exercise.eval = TRUE}
# prediksi `kelas` data train

```

Lakukan prediksi kelas dengan model tuning pada data `heart_test` dan simpan dengan nama `heart_test_new`

```{r pred_test_tuning, exercise = TRUE, exercise.eval = TRUE}
# prediksi `kelas` data test

```

Lakukan evaluasi pada model terhadap data train dan data test dengan confusion matrix. 

```{r eval_tuning, exercise = TRUE, exercise.eval = TRUE}
# confusion matrix data train

# confusion matrix data test

```

```{r question-p, echo=FALSE}
question("Apabila model masih dianggap optimal jika perbedaan nilai recall dari data train dan data test tidak lebih dari 5%. Maka berdasarkan nilai toleransi tersebut, bagaimanakah kondisi model tuning yang dihasilkan? ", type = "single",
correct = "Yaps benar!", incorrect = "Jawaban Anda masih kurang tepat.", allow_retry = TRUE,
random_answer_order = FALSE,
answer("Underfitting"),
answer("Overfitting"),
answer("Just Right", correct = TRUE))
```

Namun apabila performa model decision tree masih dianggap overfitting, maka yang dapat dilakukan adalah melakukan _hyperparameter tuning_ kembali. Kemudian jika _pruning_ juga masih belum optimal, cara lain untuk meningkatkan performa tree-based model adalah dengan _Ensemble Method_ yang akan dibahas di topik selanjutnya.

---
title: "Classification 2"
output: html_document
---

## Bab 4 : Random Forest

Random Forest adalah salah satu jenis _Ensemble Method_. Ensemble Method adalah metode yg menggabungkan prediksi dari beberapa model menjadi 1 prediksi tunggal. Metode ini bertujuan untuk menangani masalah overfitting. Analogi sederhananya, ketika sebuah keputusan diambil oleh satu orang maka akan rentan bias. Namun bila dilakukan musyawarah, maka keputusannya akan lebih bijak karena merupakan kesepakatan bersama.

Dengan konsep tersebut, Random Forest melakukan prediksi dengan membuat banyak Decision Tree. Masing-masing Decision Tree memiliki karakteristik masing-masing dan tidak saling berhubungan satu sama lain. kemudian dari sekian banyak hasil prediksi tersebut dilakukan voting. Kelas dengan jumlah terbanyak akan menjadi hasil prediksi final. 

Random Forest memanfaatkan konsep bernama Bagging: Bootstrap and Aggregation. Berikut adalah proses yang terjadi:

1. Bootstrap sampling: Membuat data dengan random sampling (with replacement) dari data keseluruhan dan mengizinkan adanya baris yang terduplikat.
2. Dibuat 1 decision tree untuk masing-masing data hasil bootstrap. Digunakan parameter `mtry` untuk memilih banyaknya calon prediktor secara random (_Automatic Feature Selection_)
3. Melakukan prediksi terhadap observasi yang baru untuk setiap Decision Tree.
4. Aggregation: Menghasilkan satu prediksi tunggal untuk memprediksi. Pada kasus klasifikasi dengan _majority voting_, sedangkan pada kasus regresi dengan mengambil rata-rata nilai target

### Study Case: Heart Disease

Pada pembelajaran metode klasifikasi dengan Random Forest, kita akan menggunakan dataset **Heart Disease** seperti yang kita gunakan pada topik Decision Tree. Namun kasusnya kali ini, kita tidak ingin melakukan interpretasi pada model, melainkan hanya ingin menghasilkan model yang _robust_ dalam melakukan prediksi terhadap pasien mengidap penyakit jantung atau tidak. Kemudian kita ingin mencari tahu variabel prediktor apa yang paling memengaruhi hasil prediksi tersebut. Untuk itu kita bisa menggunakan teknik Random Forest dalam menjawab kasus tersebut.

Untuk proses pembacaan data, cross validasi, dan upsampling silakan merujuk pada topik Decision Tree. Kita akan melanjutkan dari proses Model Fitting. 

### Model Fitting

Kali ini kita akan membuat model random forest dengan mengunakan teknik k-fold cross validation. K-fold cross validation adalah metode cross validation dimana data akan dibagi menjadi $k$ bagian sama banyak. Metode ini memberlakukan seluruh data pernah menjadi data train dan data test. Tujuannya supaya bisa mengetahui skema splitting mana yang terbaik. 

Definisikan k-fold cross validation dengan nama variabel `control`, dengan k=5 dan pembuatan set k-fold tersebut dilakukan 3 kali. Gunakan argumen `trainControl` dengan keterangan sebagai berikut:

- `method`: metode dalam melakukan cross validation
- `number`: nilai k dalam k-fold CV
- `repeats`: pengulangan dalam melakukan k-fold CV

```{r fold_heart, exercise = TRUE, exercise.eval = TRUE}
# definisikan k-fold validation
set.seed(417)
# control <- 

```

Kemudian dilakukan pembuatan model random forest dengan _code_ berikut. 

```{r eval=FALSE}
# pembuatan model random forest
heart_forest <- train(form = target~., data = heart_train_up, method = "rf",                  
                trainControl = control)
```

Tampilkan summary model dengan memanggil model yang sudah dibuat sebelumnya:
```{r echo=FALSE, message=FALSE}

# read model
heart_forest <- readRDS("rds-files/heart_forest.RDS")

# summary model
heart_forest
```

```{r question-q, echo=FALSE}
question("Berdasarkan output summary model random forest, berapa kalikah prediktor digunakan untuk splitting node pada final model?", type = "single",
correct = "Yaps benar!", incorrect = "Jawaban Anda masih kurang tepat.", allow_retry = TRUE,
random_answer_order = FALSE,
answer("2"),
answer("174", correct = TRUE),
answer("347"))
```

Selanjutnya kita bisa melihat summary final model dengan menjalankan chunk berikut:
```{r}
heart_forest$finalModel
```

Berdasarkan summary model, kita dapat mengetahui nilai out-of-bag error (OOB) yang dapat dilihat pada keterangan `OOB estimate of  error rate`. Nilai OOB adalah nilai error yg diterima oleh model terhadap _out of bag sample_  (_unseen data_ saat melakukan bootstrap sampling). Dengan mengetahui nilai OOB, maka dapat dihitung nilai akurasi dengan formula berikut:

$$Accuracy  = 100 - OOB $$
```{r question-r, echo=FALSE}
question("Berdasarkan output summary model final, berapakah nilai akurasi yang dihasilkan pada pada data test (out of bag sample)?", type = "single",
correct = "Yaps benar!", incorrect = "Jawaban Anda masih kurang tepat.", allow_retry = TRUE,
random_answer_order = FALSE,
answer("18.18%"),
answer("81.82%", correct = TRUE),
answer("99.99%"))
```

### Interpretation

Random forest adalah model yang tidak dapat diinterpretasikan, namun kita bisa melihat prediktor apa saja yang paling digunakan (penting) dalam pembuatan random forest

```{r}
varImp(heart_forest)
```

```{r question-s, echo=FALSE}
question("Dari output yang terbentuk, variabel mana yang memiliki andil paling tinggi dalam menghasilkan prediksi?", type = "single",
correct = "Yaps benar!", incorrect = "Jawaban Anda masih kurang tepat.", allow_retry = TRUE,
random_answer_order = FALSE,
answer("Kondisi Thalassemia (thal)",correct = TRUE),
answer("Kondisi Kolesterol serum (chol)"),
answer("Jenis kelamin pasien (sex)"),
answer("Kondisi Pembuluh darah (ca)"))
```

### Prediction & Model Evaluation

Lakukan prediksi model `heart_forest` terhadap `heart_train`. Simpan dengan nama variable `heart_pred_forest_train`. Lalu evaluasi model terhadap data train dengan confusion matrix

```{r pred_forest_train, exercise = TRUE, exercise.eval = TRUE}
# prediksi terhadap data train

# evaluasi model terhadap data train

```

Kemudian lakukan prediksi model `heart_forest` terhadap `heart_test`. Simpan dengan nama variable `heart_pred_forest_test`. Lakukan juga evaluasi model terhadap data test dengan confusion matrix

```{r pred_forest_test, exercise = TRUE, exercise.eval = TRUE}
# prediksi terhadap data test

# evaluasi model terhadap data test

```

```{r question-t, echo=FALSE}
question("Berdasarkan output, bagaimanakah kondisi model dalam memprediksikan data test? ", type = "single",
correct = "Yaps benar!", incorrect = "Jawaban Anda masih kurang tepat.", allow_retry = TRUE,
random_answer_order = FALSE,
answer("Underfitting"),
answer("Overfitting"),
answer("Just Right", correct = TRUE))
```

Berdasarkan hasil evaluasi model `heart_forest`, model telah berhasil melakukan prediksi dengan baik terhadap data train dan data test, dengan nilai Recall pada data test mencapai 96%. Kemudian kita juga mampu mengetahui variabel-variabel mana saja yang dianggap penting dalam melakukan prediksi.

#### Don't stop learning!
See yaa :)

